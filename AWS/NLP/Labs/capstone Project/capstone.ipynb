{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 02.14.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Bringing It All Together\n",
    "\n",
    "In this lab, you will bring together many of the tools and techniques that you have learned throughout this course into a final project. You can choose from many different paths to get to the solution. You could use AWS Managed Services, such as Amazon Comprehend, or use the Amazon SageMaker models. Have fun on whichever path you choose.\n",
    "\n",
    "### Business scenario\n",
    "\n",
    "You work for a training organization that recently developed an introductory course about machine learning (ML). The course includes more than 40 videos that cover a broad range of ML topics. You have been asked to create an application that will students can use to quickly locate and view video content by searching for topics and key phrases.\n",
    "\n",
    "You have downloaded all of the videos to an Amazon Simple Storage Service (Amazon S3) bucket. Your assignment is to produce a dashboard that meets your supervisor’s requirements.\n",
    "\n",
    "To assist you, all of the previous labs have been provided in this workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab steps\n",
    "\n",
    "To complete this lab, you will follow these steps:\n",
    "\n",
    "1. [Viewing the video files](#1.-Viewing-the-video-files)\n",
    "2. [Transcribing the videos](#2.-Transcribing-the-videos)\n",
    "3. [Normalizing the text](#3.-Normalizing-the-text)\n",
    "4. [Extracting key phrases and topics](#4.-Extracting-key-phrases-and-topics)\n",
    "5. [Creating the dashboard](#5.-Creating-the-dashboard)\n",
    "\n",
    "## Submitting your work\n",
    "\n",
    "1. In the lab console, choose **Submit** to record your progress and when prompted, choose **Yes**.\n",
    "\n",
    "1. If the results don't display after a couple of minutes, return to the top of these instructions and choose **Grades**.\n",
    "\n",
    "     **Tip**: You can submit your work multiple times. After you change your work, choose **Submit** again. Your last submission is what will be recorded for this lab.\n",
    "\n",
    "1. To find detailed feedback on your work, choose **Details** followed by **View Submission Report**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful information\n",
    "\n",
    "The following cell contains some information that might be useful as you complete this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w\"\n",
    "job_data_access_role = 'arn:aws:iam::631168390258:role/service-role/c96181a2162114l4859276t1w-ComprehendDataAccessRole-1NUXO7WC0SJKM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Viewing the video files\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source video files are located in the following shared Amazon Simple Storage Service (Amazon S3) bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-26 20:17:33  410925369 Mod01_Course Overview.mp4\n",
      "2021-04-26 20:10:02   39576695 Mod02_Intro.mp4\n",
      "2021-04-26 20:31:23  302994828 Mod02_Sect01.mp4\n",
      "2021-04-26 20:17:33  416563881 Mod02_Sect02.mp4\n",
      "2021-04-26 20:17:33  318685583 Mod02_Sect03.mp4\n",
      "2021-04-26 20:17:33  255877251 Mod02_Sect04.mp4\n",
      "2021-04-26 20:23:51   99988046 Mod02_Sect05.mp4\n",
      "2021-04-26 20:24:54   50700224 Mod02_WrapUp.mp4\n",
      "2021-04-26 20:26:27   60627667 Mod03_Intro.mp4\n",
      "2021-04-26 20:26:28  272229844 Mod03_Sect01.mp4\n",
      "2021-04-26 20:27:06  309127124 Mod03_Sect02_part1.mp4\n",
      "2021-04-26 20:27:06  195635527 Mod03_Sect02_part2.mp4\n",
      "2021-04-26 20:28:03  123924818 Mod03_Sect02_part3.mp4\n",
      "2021-04-26 20:31:28  171681915 Mod03_Sect03_part1.mp4\n",
      "2021-04-26 20:32:07  285200083 Mod03_Sect03_part2.mp4\n",
      "2021-04-26 20:33:17  105470345 Mod03_Sect03_part3.mp4\n",
      "2021-04-26 20:35:10  157185651 Mod03_Sect04_part1.mp4\n",
      "2021-04-26 20:36:27  187435635 Mod03_Sect04_part2.mp4\n",
      "2021-04-26 20:36:40  280720369 Mod03_Sect04_part3.mp4\n",
      "2021-04-26 20:40:01  443479313 Mod03_Sect05.mp4\n",
      "2021-04-26 20:40:08  234182186 Mod03_Sect06.mp4\n",
      "2021-04-26 20:40:33  207718047 Mod03_Sect07_part1.mp4\n",
      "2021-04-26 20:42:07  125592110 Mod03_Sect07_part2.mp4\n",
      "2021-04-26 20:45:10  508500301 Mod03_Sect07_part3.mp4\n",
      "2021-04-26 20:46:16  320126756 Mod03_Sect08.mp4\n",
      "2021-04-26 20:46:43   41839508 Mod03_WrapUp.mp4\n",
      "2021-04-26 20:46:55   34148489 Mod04_Intro.mp4\n",
      "2021-04-26 20:48:24   84959465 Mod04_Sect01.mp4\n",
      "2021-04-26 20:48:25  345182970 Mod04_Sect02_part1.mp4\n",
      "2021-04-26 20:51:34  218661651 Mod04_Sect02_part2.mp4\n",
      "2021-04-26 20:53:32  430140637 Mod04_Sect02_part3.mp4\n",
      "2021-04-26 20:56:03   22036605 Mod04_WrapUp.mp4\n",
      "2021-04-26 20:57:18   49187118 Mod05_Intro.mp4\n",
      "2021-04-26 20:58:19  245798071 Mod05_Sect01_ver2.mp4\n",
      "2021-04-26 20:58:50  233314835 Mod05_Sect02_part1_ver2.mp4\n",
      "2021-04-26 20:59:14  348545306 Mod05_Sect02_part2.mp4\n",
      "2021-04-26 20:59:17  239142711 Mod05_Sect03_part1.mp4\n",
      "2021-04-26 21:06:04  267533559 Mod05_Sect03_part2.mp4\n",
      "2021-04-26 21:06:06  212502220 Mod05_Sect03_part3.mp4\n",
      "2021-04-26 21:06:48  206317022 Mod05_Sect03_part4_ver2.mp4\n",
      "2021-04-26 21:06:48   60361230 Mod05_WrapUp_ver2.mp4\n",
      "2021-04-26 21:09:14   35397860 Mod06_Intro.mp4\n",
      "2021-04-26 21:09:24  845633599 Mod06_Sect01.mp4\n",
      "2021-04-26 21:10:47  326126684 Mod06_Sect02.mp4\n",
      "2021-04-26 21:12:26   19790740 Mod06_WrapUp.mp4\n",
      "2021-04-26 21:12:56  131249036 Mod07_Sect01.mp4\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transcribing the videos\n",
    " ([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to implement your solution to transcribe the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_Intro.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_Intro.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_Sect03.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_Sect03.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_Sect05.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_Sect05.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_WrapUp.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_WrapUp.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_Sect01.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_Sect01.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_Sect04.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_Sect04.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_Sect02.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_Sect02.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Intro.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Intro.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod01_Course Overview.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod01_Course Overview.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect02_part3.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect02_part3.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect02_part2.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect02_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect01.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect01.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect03_part1.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect03_part1.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect02_part1.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect02_part1.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect03_part3.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect03_part3.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect04_part1.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect04_part1.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect04_part2.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect04_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect03_part2.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect03_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect04_part3.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect04_part3.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect07_part2.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect07_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect06.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect06.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect07_part1.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect07_part1.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_WrapUp.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_WrapUp.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod04_Intro.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod04_Intro.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect05.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect05.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod04_Sect01.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod04_Sect01.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect08.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect08.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod04_Sect02_part3.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod04_Sect02_part3.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod04_Sect02_part1.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod04_Sect02_part1.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod04_WrapUp.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod04_WrapUp.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect02_part1_ver2.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect02_part1_ver2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect07_part3.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect07_part3.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect03_part1.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect03_part1.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Intro.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Intro.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect03_part2.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect03_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod04_Sect02_part2.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod04_Sect02_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect02_part2.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect02_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_WrapUp_ver2.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_WrapUp_ver2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod06_Intro.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod06_Intro.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect03_part3.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect03_part3.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect01_ver2.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect01_ver2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod06_WrapUp.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod06_WrapUp.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect03_part4_ver2.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect03_part4_ver2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod07_Sect01.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod07_Sect01.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod06_Sect02.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod06_Sect02.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod06_Sect01.mp4 to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod06_Sect01.mp4\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/ s3://{bucket}/input/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input/Mod01_Course Overview.mp4\n",
      "input/Mod02_Intro.mp4\n",
      "input/Mod02_Sect01.mp4\n",
      "input/Mod02_Sect02.mp4\n",
      "input/Mod02_Sect03.mp4\n",
      "input/Mod02_Sect04.mp4\n",
      "input/Mod02_Sect05.mp4\n",
      "input/Mod02_WrapUp.mp4\n",
      "input/Mod03_Intro.mp4\n",
      "input/Mod03_Sect01.mp4\n",
      "input/Mod03_Sect02_part1.mp4\n",
      "input/Mod03_Sect02_part2.mp4\n",
      "input/Mod03_Sect02_part3.mp4\n",
      "input/Mod03_Sect03_part1.mp4\n",
      "input/Mod03_Sect03_part2.mp4\n",
      "input/Mod03_Sect03_part3.mp4\n",
      "input/Mod03_Sect04_part1.mp4\n",
      "input/Mod03_Sect04_part2.mp4\n",
      "input/Mod03_Sect04_part3.mp4\n",
      "input/Mod03_Sect05.mp4\n",
      "input/Mod03_Sect06.mp4\n",
      "input/Mod03_Sect07_part1.mp4\n",
      "input/Mod03_Sect07_part2.mp4\n",
      "input/Mod03_Sect07_part3.mp4\n",
      "input/Mod03_Sect08.mp4\n",
      "input/Mod03_WrapUp.mp4\n",
      "input/Mod04_Intro.mp4\n",
      "input/Mod04_Sect01.mp4\n",
      "input/Mod04_Sect02_part1.mp4\n",
      "input/Mod04_Sect02_part2.mp4\n",
      "input/Mod04_Sect02_part3.mp4\n",
      "input/Mod04_WrapUp.mp4\n",
      "input/Mod05_Intro.mp4\n",
      "input/Mod05_Sect01_ver2.mp4\n",
      "input/Mod05_Sect02_part1_ver2.mp4\n",
      "input/Mod05_Sect02_part2.mp4\n",
      "input/Mod05_Sect03_part1.mp4\n",
      "input/Mod05_Sect03_part2.mp4\n",
      "input/Mod05_Sect03_part3.mp4\n",
      "input/Mod05_Sect03_part4_ver2.mp4\n",
      "input/Mod05_WrapUp_ver2.mp4\n",
      "input/Mod06_Intro.mp4\n",
      "input/Mod06_Sect01.mp4\n",
      "input/Mod06_Sect02.mp4\n",
      "input/Mod06_WrapUp.mp4\n",
      "input/Mod07_Sect01.mp4\n"
     ]
    }
   ],
   "source": [
    "from boto3 import client\n",
    "\n",
    "conn = client('s3') \n",
    "for key in conn.list_objects(Bucket=bucket)['Contents']:\n",
    "    print(key['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os, io, struct, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "from time import sleep\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe_client = boto3.client(\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod01_Course Overview.mp4 transcribed to transcribed-input/Mod01_Course_Overview.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_Intro.mp4 transcribed to transcribed-input/Mod02_Intro.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_Sect01.mp4 transcribed to transcribed-input/Mod02_Sect01.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_Sect02.mp4 transcribed to transcribed-input/Mod02_Sect02.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_Sect03.mp4 transcribed to transcribed-input/Mod02_Sect03.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_Sect04.mp4 transcribed to transcribed-input/Mod02_Sect04.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_Sect05.mp4 transcribed to transcribed-input/Mod02_Sect05.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod02_WrapUp.mp4 transcribed to transcribed-input/Mod02_WrapUp.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Intro.mp4 transcribed to transcribed-input/Mod03_Intro.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect01.mp4 transcribed to transcribed-input/Mod03_Sect01.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect02_part1.mp4 transcribed to transcribed-input/Mod03_Sect02_part1.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect02_part2.mp4 transcribed to transcribed-input/Mod03_Sect02_part2.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect02_part3.mp4 transcribed to transcribed-input/Mod03_Sect02_part3.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect03_part1.mp4 transcribed to transcribed-input/Mod03_Sect03_part1.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect03_part2.mp4 transcribed to transcribed-input/Mod03_Sect03_part2.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect03_part3.mp4 transcribed to transcribed-input/Mod03_Sect03_part3.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect04_part1.mp4 transcribed to transcribed-input/Mod03_Sect04_part1.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect04_part2.mp4 transcribed to transcribed-input/Mod03_Sect04_part2.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect04_part3.mp4 transcribed to transcribed-input/Mod03_Sect04_part3.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect05.mp4 transcribed to transcribed-input/Mod03_Sect05.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect06.mp4 transcribed to transcribed-input/Mod03_Sect06.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect07_part1.mp4 transcribed to transcribed-input/Mod03_Sect07_part1.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect07_part2.mp4 transcribed to transcribed-input/Mod03_Sect07_part2.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect07_part3.mp4 transcribed to transcribed-input/Mod03_Sect07_part3.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_Sect08.mp4 transcribed to transcribed-input/Mod03_Sect08.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod03_WrapUp.mp4 transcribed to transcribed-input/Mod03_WrapUp.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod04_Intro.mp4 transcribed to transcribed-input/Mod04_Intro.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod04_Sect01.mp4 transcribed to transcribed-input/Mod04_Sect01.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod04_Sect02_part1.mp4 transcribed to transcribed-input/Mod04_Sect02_part1.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod04_Sect02_part2.mp4 transcribed to transcribed-input/Mod04_Sect02_part2.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod04_Sect02_part3.mp4 transcribed to transcribed-input/Mod04_Sect02_part3.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod04_WrapUp.mp4 transcribed to transcribed-input/Mod04_WrapUp.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Intro.mp4 transcribed to transcribed-input/Mod05_Intro.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect01_ver2.mp4 transcribed to transcribed-input/Mod05_Sect01_ver2.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect02_part1_ver2.mp4 transcribed to transcribed-input/Mod05_Sect02_part1_ver2.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect02_part2.mp4 transcribed to transcribed-input/Mod05_Sect02_part2.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect03_part1.mp4 transcribed to transcribed-input/Mod05_Sect03_part1.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect03_part2.mp4 transcribed to transcribed-input/Mod05_Sect03_part2.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect03_part3.mp4 transcribed to transcribed-input/Mod05_Sect03_part3.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_Sect03_part4_ver2.mp4 transcribed to transcribed-input/Mod05_Sect03_part4_ver2.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod05_WrapUp_ver2.mp4 transcribed to transcribed-input/Mod05_WrapUp_ver2.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod06_Intro.mp4 transcribed to transcribed-input/Mod06_Intro.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod06_Sect01.mp4 transcribed to transcribed-input/Mod06_Sect01.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod06_Sect02.mp4 transcribed to transcribed-input/Mod06_Sect02.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod06_WrapUp.mp4 transcribed to transcribed-input/Mod06_WrapUp.txt\n",
      "s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/input/Mod07_Sect01.mp4 transcribed to transcribed-input/Mod07_Sect01.txt\n"
     ]
    }
   ],
   "source": [
    "output_files=[]\n",
    "transcribe_output_prefix = 'transcribed'\n",
    "for key in conn.list_objects_v2(Bucket=bucket, Prefix='input')['Contents']:\n",
    "    if 'temp' in key['Key']:\n",
    "        continue\n",
    "    object_name=key['Key']\n",
    "    media_input_uri = f's3://{bucket}/{object_name}'\n",
    "\n",
    "    #create the transcription job\n",
    "    job_uuid = uuid.uuid1()\n",
    "    transcribe_job_name = f\"transcribe-job-{job_uuid}\"\n",
    "    output_file = object_name.split('.')[0].replace(\" \",\"_\")\n",
    "    transcribe_output_filename = f'{transcribe_output_prefix}-{output_file}.txt'\n",
    "    output_files.append([transcribe_output_filename,object_name,\"\"])\n",
    "    print(f'{media_input_uri} transcribed to {transcribe_output_filename}')\n",
    "\n",
    "    response = transcribe_client.start_transcription_job(\n",
    "        TranscriptionJobName=transcribe_job_name,\n",
    "        Media={'MediaFileUri': media_input_uri},\n",
    "        MediaFormat='mp4',\n",
    "        LanguageCode='en-US',\n",
    "        OutputBucketName=bucket,\n",
    "        OutputKey=transcribe_output_filename\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['transcribed-input/Mod01_Course_Overview.txt', 'input/Mod01_Course Overview.mp4', ''], ['transcribed-input/Mod02_Intro.txt', 'input/Mod02_Intro.mp4', ''], ['transcribed-input/Mod02_Sect01.txt', 'input/Mod02_Sect01.mp4', ''], ['transcribed-input/Mod02_Sect02.txt', 'input/Mod02_Sect02.mp4', ''], ['transcribed-input/Mod02_Sect03.txt', 'input/Mod02_Sect03.mp4', ''], ['transcribed-input/Mod02_Sect04.txt', 'input/Mod02_Sect04.mp4', ''], ['transcribed-input/Mod02_Sect05.txt', 'input/Mod02_Sect05.mp4', ''], ['transcribed-input/Mod02_WrapUp.txt', 'input/Mod02_WrapUp.mp4', ''], ['transcribed-input/Mod03_Intro.txt', 'input/Mod03_Intro.mp4', ''], ['transcribed-input/Mod03_Sect01.txt', 'input/Mod03_Sect01.mp4', ''], ['transcribed-input/Mod03_Sect02_part1.txt', 'input/Mod03_Sect02_part1.mp4', ''], ['transcribed-input/Mod03_Sect02_part2.txt', 'input/Mod03_Sect02_part2.mp4', ''], ['transcribed-input/Mod03_Sect02_part3.txt', 'input/Mod03_Sect02_part3.mp4', ''], ['transcribed-input/Mod03_Sect03_part1.txt', 'input/Mod03_Sect03_part1.mp4', ''], ['transcribed-input/Mod03_Sect03_part2.txt', 'input/Mod03_Sect03_part2.mp4', ''], ['transcribed-input/Mod03_Sect03_part3.txt', 'input/Mod03_Sect03_part3.mp4', ''], ['transcribed-input/Mod03_Sect04_part1.txt', 'input/Mod03_Sect04_part1.mp4', ''], ['transcribed-input/Mod03_Sect04_part2.txt', 'input/Mod03_Sect04_part2.mp4', ''], ['transcribed-input/Mod03_Sect04_part3.txt', 'input/Mod03_Sect04_part3.mp4', ''], ['transcribed-input/Mod03_Sect05.txt', 'input/Mod03_Sect05.mp4', ''], ['transcribed-input/Mod03_Sect06.txt', 'input/Mod03_Sect06.mp4', ''], ['transcribed-input/Mod03_Sect07_part1.txt', 'input/Mod03_Sect07_part1.mp4', ''], ['transcribed-input/Mod03_Sect07_part2.txt', 'input/Mod03_Sect07_part2.mp4', ''], ['transcribed-input/Mod03_Sect07_part3.txt', 'input/Mod03_Sect07_part3.mp4', ''], ['transcribed-input/Mod03_Sect08.txt', 'input/Mod03_Sect08.mp4', ''], ['transcribed-input/Mod03_WrapUp.txt', 'input/Mod03_WrapUp.mp4', ''], ['transcribed-input/Mod04_Intro.txt', 'input/Mod04_Intro.mp4', ''], ['transcribed-input/Mod04_Sect01.txt', 'input/Mod04_Sect01.mp4', ''], ['transcribed-input/Mod04_Sect02_part1.txt', 'input/Mod04_Sect02_part1.mp4', ''], ['transcribed-input/Mod04_Sect02_part2.txt', 'input/Mod04_Sect02_part2.mp4', ''], ['transcribed-input/Mod04_Sect02_part3.txt', 'input/Mod04_Sect02_part3.mp4', ''], ['transcribed-input/Mod04_WrapUp.txt', 'input/Mod04_WrapUp.mp4', ''], ['transcribed-input/Mod05_Intro.txt', 'input/Mod05_Intro.mp4', ''], ['transcribed-input/Mod05_Sect01_ver2.txt', 'input/Mod05_Sect01_ver2.mp4', ''], ['transcribed-input/Mod05_Sect02_part1_ver2.txt', 'input/Mod05_Sect02_part1_ver2.mp4', ''], ['transcribed-input/Mod05_Sect02_part2.txt', 'input/Mod05_Sect02_part2.mp4', ''], ['transcribed-input/Mod05_Sect03_part1.txt', 'input/Mod05_Sect03_part1.mp4', ''], ['transcribed-input/Mod05_Sect03_part2.txt', 'input/Mod05_Sect03_part2.mp4', ''], ['transcribed-input/Mod05_Sect03_part3.txt', 'input/Mod05_Sect03_part3.mp4', ''], ['transcribed-input/Mod05_Sect03_part4_ver2.txt', 'input/Mod05_Sect03_part4_ver2.mp4', ''], ['transcribed-input/Mod05_WrapUp_ver2.txt', 'input/Mod05_WrapUp_ver2.mp4', ''], ['transcribed-input/Mod06_Intro.txt', 'input/Mod06_Intro.mp4', ''], ['transcribed-input/Mod06_Sect01.txt', 'input/Mod06_Sect01.mp4', ''], ['transcribed-input/Mod06_Sect02.txt', 'input/Mod06_Sect02.mp4', ''], ['transcribed-input/Mod06_WrapUp.txt', 'input/Mod06_WrapUp.mp4', ''], ['transcribed-input/Mod07_Sect01.txt', 'input/Mod07_Sect01.mp4', '']]\n"
     ]
    }
   ],
   "source": [
    "print(output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".COMPLETED\n"
     ]
    }
   ],
   "source": [
    "job=None\n",
    "while True:\n",
    "    job = transcribe_client.get_transcription_job(TranscriptionJobName = transcribe_job_name)\n",
    "    if job['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED','FAILED']:\n",
    "        break\n",
    "    print('.', end='')\n",
    "    sleep(20)\n",
    "        \n",
    "print(job['TranscriptionJob']['TranscriptionJobStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transcribed-input/Mod01_Course_Overview.txt', 'input/Mod01_Course Overview.mp4', \"Hi and welcome to Amazon Academy of Machine Learning Foundations in this module, you'll learn about the course objectives, various job roles in the machine learning domain and where you can go to learn more about machine learning. After completing this module, you should be able to identify course prerequisites and objectives indicate the role of the data scientist in business and identify resources for further learning. We're now going to look at the prerequisites for taking this course. Before you take this course, we recommend that you first complete Aws Academy Cloud Foundations. You should also have some general technical knowledge of it including foundational computer literacy skills like basic computer concepts, email file management and a good understanding of the internet. We also recommend that you have intermediate skills with Python programming and a general knowledge of applied statistics. Finally, general business knowledge is important for this course. This includes insight into how information technology is used in business. It's also important to have business related skill sets such as communication skills, leadership skills, and an orientation towards customer service. In this course, you'll be introduced to the key concepts of machine learning, its tools and its uses you'll also be introduced to and work with some of the AWS services for machine learning. You'll learn how to recognize how machine learning and deep learning are part of artificial intelligence. Describe artificial intelligence and machine learning terminology. Identify how machine learning can be used to solve a business problem. Describe the machine learning process. List the tools available to data scientists and identify when to use machine learning instead of traditional software development methods. As part of this course, you'll also learn how to implement a machine learning pipeline. This includes how to formulate a problem from a business request, obtain and secure data for machine learning, build a Jupiter notebook by using Amazon Sagemaker outline the process for evaluating data. Explain why data needs to be pre processed and use open source tools to examine and prep process data. You will also use Amazon's Sage maker to train and host a machine learning model, use cross validation to test the performance of a machine learning model. Use a hosted model for inference, create an Amazon Sage maker hyper parameter tuning job to optimize a model's effectiveness. And finally how to use managed Amazon machine learning services to solve specific machine learning problems in forecasting computer vision and natural language processing. We'll now review the course outline to achieve the course objectives. You'll complete the following modules to start in module two, you'll get an introduction to machine learning in module three. You'll learn how to implement a machine learning pipeline with Amazon Sagemaker modules 45 and six describe how to apply managed Amazon machine learning services for problems in forecasting computer vision and natural language processing. Finally, module seven is a summary of the course. It also includes an overview of steps you can take to work towards the AWS certified machine learning specialty. The next five slides provide more detail about the subtopics covered in each module. The purpose of module two is to introduce you to major concepts for understanding machine learning. Section one describes the overall field of machine learning and how machine learning relates to artificial intelligence and deep learning. In section two, you'll learn about some of the most common business problems you can solve with machine learning. Section three describes the general workflow for solving machine learning problems. You'll also learn some of the more common machine learning terms. In section four, you'll review some of the commonly used tools by machine learning professionals. And lastly in section five, you'll get an overview of some of the common challenges you'll face when working with machine learning problems. In module three, you'll get an introduction to Amazon's sagemaker and how you can use it to implement a machine learning pipeline. The module focuses on the application of machine learning to solve problems with several public domain data sets. As examples of the machine learning pipeline. Section one introduces you to defining business problems and the data sets we will use during this module. Section two through eight described the phases of the machine learning pipeline by using computer vision as an example application. In section two, you'll learn how to collect and secure data. Section three describes different techniques for evaluating data. In section four, you'll learn about the process of feature engineering. Section five described the steps he'll take to train a model with Sagemaker. In section six, you'll get an overview of the options in Sagemaker for hosting and using a model. Finally, section seven and eight cover how to evaluate and tune your model with Sagemaker. In this module, you'll be introduced to using machine learning to create forecasts based on a time series data. In section one, you'll be introduced to forecasting in some of its common applications. Section two outlined some of the pitfalls of using time series data to make forecasts. Finally, in section three, you'll get an overview of how to use Amazon forecast in this module, you'll learn about using machine learning for computer vision. Section one describes the general problems you can solve with computer vision. In section two, you'll learn about the process for analyzing images and videos. And in section three, you'll learn the steps you'll need to take to prepare data sets for computer vision. In this module, you'll be introduced to natural language processing with machine learning. In section one, you'll learn about the general set of problems you can solve with natural language processing. Section two reviews some of the managed Amazon machine learning services you can use to address natural language processing problems. These services include Amazon, transcribe, Amazon translate, Amazon, Lex, Amazon comprehend and Amazon Poly module seven is the final module of the course. In this module, you'll review what you've learned throughout this course. You'll also be introduced to the next steps you should take. If you want to achieve the AWS Certified Machine learning specialty section. One of this module summarizes the topics you've covered in this course. In section two, you'll learn more about the Aws documentation. You'll also review two common frameworks for applying Aws services. And finally, section three describes the steps you should take. If you want to continue working towards the Aws certified machine learning specialty in this section, you'll learn about some of the more common job roles for machine learning professionals. If you're interested in a data scientist role, focus on developing analytical statistical and programming skills. As a data scientist, you'll use those skills to collect analyze and interpret large data sets. Some universities now offer degrees in data science, but data scientists often have degrees in related fields like statistics, math, computer science or economics. As a data scientist, you'll need technical competencies in statistics, machine learning programming languages and data analytics. If you'd like to have a career as a machine learning engineer, the skills you'll need will be similar to a data scientist skill set like data scientists, machine learning engineers also require technical competencies in statistics and machine learning. However, you'll focus more on programming skills and software architecture than analysis and interpretation. As a machine learning engineer, you'll apply those programming and architecture skills to design and develop machine learning systems. Machine learning engineers often have previous experience with software development and they rely more heavily on programming and software engineering than other machine learning roles. You might also be interested in a career in science where you can apply machine learning technology to your field. Machine learning is having an impact in everything from astronomy to zoology. So there are many different paths open to you. As an applied science researcher, your primary focus will be on the type of science you're working on. You'll need some of the same skills as a data scientist, but you'll also need to know how to apply those skills to your chosen domain. Thus, applied science roles also require technical competencies in statistics and machine learning. Many software developers are now integrating machine learning into their applications. If you're interested in a career as a software developer, you should also include machine learning technology in your studies. As a machine learning developer, your primary focus will be software development skills, but you'll also need some of the same skills as a data scientist. So make sure you take course work in statistics and applied mathematics. And here's a final note for this module, we recommend reviewing your student guide in your student guide, you'll find links to documentation and other resources you'll use throughout the course. That's it for this introduction. Thanks for watching. We'll see you in the next video.\"]\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "transcribed_text = []\n",
    "for transcribe_output_filename in output_files:\n",
    "    result = s3_client.get_object(Bucket=bucket, Key=transcribe_output_filename[0]) \n",
    "    data = json.load(result['Body']) \n",
    "    transcription = data['results']['transcripts'][0]['transcript']\n",
    "    transcribe_output_filename[2] = transcription\n",
    "\n",
    "print(output_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalizing the text\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to perform any text normalization steps that are necessary for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data=output_files, columns=['OutputFile','Video','Transcription'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OutputFile</th>\n",
       "      <th>Video</th>\n",
       "      <th>Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transcribed-input/Mod01_Course_Overview.txt</td>\n",
       "      <td>input/Mod01_Course Overview.mp4</td>\n",
       "      <td>Hi and welcome to Amazon Academy of Machine Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transcribed-input/Mod02_Intro.txt</td>\n",
       "      <td>input/Mod02_Intro.mp4</td>\n",
       "      <td>Hi and welcome to module two of Aws Academy ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transcribed-input/Mod02_Sect01.txt</td>\n",
       "      <td>input/Mod02_Sect01.mp4</td>\n",
       "      <td>Hi and welcome to section one in this section....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transcribed-input/Mod02_Sect02.txt</td>\n",
       "      <td>input/Mod02_Sect02.mp4</td>\n",
       "      <td>Hi and welcome back in this section. We're goi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transcribed-input/Mod02_Sect03.txt</td>\n",
       "      <td>input/Mod02_Sect03.mp4</td>\n",
       "      <td>Hi and welcome back. This is section three and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    OutputFile  \\\n",
       "0  transcribed-input/Mod01_Course_Overview.txt   \n",
       "1            transcribed-input/Mod02_Intro.txt   \n",
       "2           transcribed-input/Mod02_Sect01.txt   \n",
       "3           transcribed-input/Mod02_Sect02.txt   \n",
       "4           transcribed-input/Mod02_Sect03.txt   \n",
       "\n",
       "                             Video  \\\n",
       "0  input/Mod01_Course Overview.mp4   \n",
       "1            input/Mod02_Intro.mp4   \n",
       "2           input/Mod02_Sect01.mp4   \n",
       "3           input/Mod02_Sect02.mp4   \n",
       "4           input/Mod02_Sect03.mp4   \n",
       "\n",
       "                                       Transcription  \n",
       "0  Hi and welcome to Amazon Academy of Machine Le...  \n",
       "1  Hi and welcome to module two of Aws Academy ma...  \n",
       "2  Hi and welcome to section one in this section....  \n",
       "3  Hi and welcome back in this section. We're goi...  \n",
       "4  Hi and welcome back. This is section three and...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(content):\n",
    "    text = re.sub(r\"http\\S+\", \"\", content ) # Remove urls\n",
    "    text = text.lower() # Lowercase \n",
    "    text = text.strip() # Remove leading/trailing whitespace\n",
    "    text = re.sub('\\s+', ' ', text) # Remove extra space and tabs\n",
    "    text = re.sub('\\n',' ',text) # remove newlines\n",
    "    text = re.compile('<.*?>').sub('', text) # Remove HTML tags/markups:\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 ms, sys: 18 µs, total: 14 ms\n",
      "Wall time: 13.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['Transcription_normalized'] = df['Transcription'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OutputFile</th>\n",
       "      <th>Video</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>Transcription_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transcribed-input/Mod01_Course_Overview.txt</td>\n",
       "      <td>input/Mod01_Course Overview.mp4</td>\n",
       "      <td>Hi and welcome to Amazon Academy of Machine Learning Foundations in this module, you'll learn about the course objectives, various job roles in th...</td>\n",
       "      <td>hi and welcome to amazon academy of machine learning foundations in this module, you'll learn about the course objectives, various job roles in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transcribed-input/Mod02_Intro.txt</td>\n",
       "      <td>input/Mod02_Intro.mp4</td>\n",
       "      <td>Hi and welcome to module two of Aws Academy machine learning in this module, we're going to introduce machine learning. We'll first look at the bu...</td>\n",
       "      <td>hi and welcome to module two of aws academy machine learning in this module, we're going to introduce machine learning. we'll first look at the bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transcribed-input/Mod02_Sect01.txt</td>\n",
       "      <td>input/Mod02_Sect01.mp4</td>\n",
       "      <td>Hi and welcome to section one in this section. We're going to talk about what machine learning is. This course is an introduction to machine learn...</td>\n",
       "      <td>hi and welcome to section one in this section. we're going to talk about what machine learning is. this course is an introduction to machine learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transcribed-input/Mod02_Sect02.txt</td>\n",
       "      <td>input/Mod02_Sect02.mp4</td>\n",
       "      <td>Hi and welcome back in this section. We're going to look at the types of business problems. Machine learning can help you solve. Machine learning ...</td>\n",
       "      <td>hi and welcome back in this section. we're going to look at the types of business problems. machine learning can help you solve. machine learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transcribed-input/Mod02_Sect03.txt</td>\n",
       "      <td>input/Mod02_Sect03.mp4</td>\n",
       "      <td>Hi and welcome back. This is section three and we're going to give you a quick high level overview of machine learning terminology and a typical w...</td>\n",
       "      <td>hi and welcome back. this is section three and we're going to give you a quick high level overview of machine learning terminology and a typical w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    OutputFile  \\\n",
       "0  transcribed-input/Mod01_Course_Overview.txt   \n",
       "1            transcribed-input/Mod02_Intro.txt   \n",
       "2           transcribed-input/Mod02_Sect01.txt   \n",
       "3           transcribed-input/Mod02_Sect02.txt   \n",
       "4           transcribed-input/Mod02_Sect03.txt   \n",
       "\n",
       "                             Video  \\\n",
       "0  input/Mod01_Course Overview.mp4   \n",
       "1            input/Mod02_Intro.mp4   \n",
       "2           input/Mod02_Sect01.mp4   \n",
       "3           input/Mod02_Sect02.mp4   \n",
       "4           input/Mod02_Sect03.mp4   \n",
       "\n",
       "                                                                                                                                           Transcription  \\\n",
       "0  Hi and welcome to Amazon Academy of Machine Learning Foundations in this module, you'll learn about the course objectives, various job roles in th...   \n",
       "1  Hi and welcome to module two of Aws Academy machine learning in this module, we're going to introduce machine learning. We'll first look at the bu...   \n",
       "2  Hi and welcome to section one in this section. We're going to talk about what machine learning is. This course is an introduction to machine learn...   \n",
       "3  Hi and welcome back in this section. We're going to look at the types of business problems. Machine learning can help you solve. Machine learning ...   \n",
       "4  Hi and welcome back. This is section three and we're going to give you a quick high level overview of machine learning terminology and a typical w...   \n",
       "\n",
       "                                                                                                                                Transcription_normalized  \n",
       "0  hi and welcome to amazon academy of machine learning foundations in this module, you'll learn about the course objectives, various job roles in th...  \n",
       "1  hi and welcome to module two of aws academy machine learning in this module, we're going to introduce machine learning. we'll first look at the bu...  \n",
       "2  hi and welcome to section one in this section. we're going to talk about what machine learning is. this course is an introduction to machine learn...  \n",
       "3  hi and welcome back in this section. we're going to look at the types of business problems. machine learning can help you solve. machine learning ...  \n",
       "4  hi and welcome back. this is section three and we're going to give you a quick high level overview of machine learning terminology and a typical w...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 150)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting key phrases and topics\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to extract the key phrases and topics from the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "def upload_comprehend_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    \n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded input to s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/capstone/comprehend/comprehend_input.csv\n"
     ]
    }
   ],
   "source": [
    "comprehend_file = 'comprehend_input.csv'\n",
    "prefix='capstone'\n",
    "upload_comprehend_s3_csv(comprehend_file, 'comprehend', df['Transcription_normalized'].str.slice(0,5000))\n",
    "test_url = f's3://{bucket}/{prefix}/comprehend/{comprehend_file}'\n",
    "print(f'Uploaded input to {test_url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehend client information\n",
    "comprehend_client = boto3.client(service_name=\"comprehend\")\n",
    "\n",
    "# Other job parameters\n",
    "input_data_format = 'ONE_DOC_PER_LINE'\n",
    "job_uuid = uuid.uuid1()\n",
    "job_name = f\"kpe-job-{job_uuid}\"\n",
    "input_data_s3_path = test_url\n",
    "output_data_s3_path = f's3://{bucket}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin the inference job\n",
    "kpe_response = comprehend_client.start_key_phrases_detection_job(\n",
    "    InputDataConfig={'S3Uri': input_data_s3_path,\n",
    "                     'InputFormat': input_data_format},\n",
    "    OutputDataConfig={'S3Uri': output_data_s3_path},\n",
    "    DataAccessRoleArn=job_data_access_role,\n",
    "    JobName=job_name,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "\n",
    "# Get the job ID\n",
    "kpe_job_id = kpe_response['JobId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = f'entity-job-{job_uuid}'\n",
    "entity_response = comprehend_client.start_entities_detection_job(\n",
    "    InputDataConfig={'S3Uri': input_data_s3_path,\n",
    "                     'InputFormat': input_data_format},\n",
    "    OutputDataConfig={'S3Uri': output_data_s3_path},\n",
    "    DataAccessRoleArn=job_data_access_role,\n",
    "    JobName=job_name,\n",
    "    LanguageCode='en'\n",
    ")\n",
    "# Get the job ID\n",
    "entity_job_id = entity_response['JobId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the dashboard\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to create the dashboard for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ip = \"YOUR IP/24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (23.2)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/50/c2/e06851e8cc28dcad7c155f4753da8833ac06a5c704c109313b8d5a62968a/pip-23.2.1-py3-none-any.whl.metadata\n",
      "  Downloading pip-23.2.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2\n",
      "    Uninstalling pip-23.2:\n",
      "      Successfully uninstalled pip-23.2\n",
      "Successfully installed pip-23.2.1\n",
      "Collecting opensearch\n",
      "  Downloading opensearch-0.9.2.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: opensearch\n",
      "  Building wheel for opensearch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for opensearch: filename=opensearch-0.9.2-py3-none-any.whl size=39842 sha256=2abe7879b055c7dfca198e55bc80aab4792d8d721ef3d191c5bc068607041576\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/83/d7/57/c1c8e01cdae22d9c55b7d0b494de94c668c3cc4cdd10aa1425\n",
      "Successfully built opensearch\n",
      "Installing collected packages: opensearch\n",
      "Successfully installed opensearch-0.9.2\n",
      "Collecting opensearch-py\n",
      "  Obtaining dependency information for opensearch-py from https://files.pythonhosted.org/packages/23/a1/18afd74d63ad21978d506b59f6d1bfa028463cff20bdd7dd59ff62087738/opensearch_py-2.3.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading opensearch_py-2.3.1-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3<2,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py) (1.26.14)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py) (2.31.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py) (3.4)\n",
      "Downloading opensearch_py-2.3.1-py2.py3-none-any.whl (327 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.3/327.3 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opensearch-py\n",
      "Successfully installed opensearch-py-2.3.1\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests) (2023.5.7)\n",
      "Collecting requests-aws4auth\n",
      "  Downloading requests_aws4auth-1.2.3-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests-aws4auth) (2.31.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests-aws4auth) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->requests-aws4auth) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->requests-aws4auth) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->requests-aws4auth) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->requests-aws4auth) (2023.5.7)\n",
      "Installing collected packages: requests-aws4auth\n",
      "Successfully installed requests-aws4auth-1.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install opensearch\n",
    "!pip install opensearch-py\n",
    "!pip install requests\n",
    "!pip install requests-aws4auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = boto3.client('es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Sid\": \"\",\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"AWS\": \"*\"\n",
    "                },\n",
    "                \"Action\": \"es:*\",\n",
    "                \"Resource\": \"*\",\n",
    "                \"Condition\": { \"IpAddress\": { \"aws:SourceIp\": my_ip } }\n",
    "            }\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = es_client.create_elasticsearch_domain(\n",
    "    DomainName = 'nlp-lab',\n",
    "    ElasticsearchVersion = '7.9',\n",
    "    ElasticsearchClusterConfig={\n",
    "        \"InstanceType\": 'm3.large.elasticsearch',\n",
    "        \"InstanceCount\": 2,\n",
    "        \"DedicatedMasterEnabled\": False,\n",
    "        \"ZoneAwarenessEnabled\": False\n",
    "    },\n",
    "    AccessPolicies = json.dumps(access_policy)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................Ready\n"
     ]
    }
   ],
   "source": [
    "# Get current job status\n",
    "kpe_job = comprehend_client.describe_key_phrases_detection_job(JobId=kpe_job_id)\n",
    "\n",
    "# Loop until job is completed\n",
    "waited = 0\n",
    "timeout_minutes = 30\n",
    "while kpe_job['KeyPhrasesDetectionJobProperties']['JobStatus'] != 'COMPLETED':\n",
    "    sleep(10)\n",
    "    waited += 10\n",
    "    assert waited//60 < timeout_minutes, \"Job timed out after %d seconds.\" % waited\n",
    "    print('.', end='')\n",
    "    kpe_job = comprehend_client.describe_key_phrases_detection_job(JobId=kpe_job_id)\n",
    "\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ],
   "source": [
    "# Get current job status\n",
    "entity_job = comprehend_client.describe_entities_detection_job(JobId=entity_job_id)\n",
    "\n",
    "# Loop until job is completed\n",
    "waited = 0\n",
    "timeout_minutes = 30\n",
    "while entity_job['EntitiesDetectionJobProperties']['JobStatus'] != 'COMPLETED':\n",
    "    sleep(10)\n",
    "    waited += 10\n",
    "    assert waited//60 < timeout_minutes, \"Job timed out after %d seconds.\" % waited\n",
    "    print('.', end='')\n",
    "    entity_job = comprehend_client.describe_entities_detection_job(JobId=entity_job_id)\n",
    "\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output filename: s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/631168390258-KP-9e71dbef753c758702e35eb78411b535/output/output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "kpe_comprehend_output_file = kpe_job['KeyPhrasesDetectionJobProperties']['OutputDataConfig']['S3Uri']\n",
    "print(f'output filename: {kpe_comprehend_output_file}')\n",
    "\n",
    "kpe_comprehend_bucket, kpe_comprehend_key = kpe_comprehend_output_file.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "\n",
    "s3r = boto3.resource('s3')\n",
    "s3r.meta.client.download_file(kpe_comprehend_bucket, kpe_comprehend_key, 'output-kpe.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tar file\n",
    "import tarfile\n",
    "tf = tarfile.open('output-kpe.tar.gz')\n",
    "tf.extractall()\n",
    "# Rename the output\n",
    "!mv 'output' 'kpe_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output filename: s3://c96181a2162114l4859276t1w631168390258-labbucket-420z8rnx845w/631168390258-NER-4d2169985facf939b9cf8ef12f94c9c6/output/output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "entity_comprehend_output_file = entity_job['EntitiesDetectionJobProperties']['OutputDataConfig']['S3Uri']\n",
    "print(f'output filename: {entity_comprehend_output_file}')\n",
    "\n",
    "entity_comprehend_bucket, entity_comprehend_key = entity_comprehend_output_file.replace(\"s3://\", \"\").split(\"/\", 1)\n",
    "\n",
    "s3r = boto3.resource('s3')\n",
    "s3r.meta.client.download_file(entity_comprehend_bucket, entity_comprehend_key, 'output-entity.tar.gz')\n",
    "\n",
    "# Extract the tar file\n",
    "import tarfile\n",
    "tf = tarfile.open('output-entity.tar.gz')\n",
    "tf.extractall()\n",
    "# Rename the output\n",
    "!mv 'output' 'entity_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = []\n",
    "with open ('kpe_output', \"r\") as myfile:\n",
    "    for line in myfile:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KeyPhrases</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'BeginOffset': 26, 'EndOffset': 33, 'Score': 0.8727456819495607, 'Text': 'academy'}, {'BeginOffset': 37, 'EndOffset': 65, 'Score': 0.75145980506...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.6214939014751475, 'Text': 'module two'}, {'BeginOffset': 33, 'EndOffset': 52, 'Score': 0.99413129...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.9589880415051381, 'Text': 'section three'}, {'BeginOffset': 72, 'EndOffset': 99, 'Score': 0.99856...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'BeginOffset': 17, 'EndOffset': 29, 'Score': 0.9997500325485067, 'Text': 'this section'}, {'BeginOffset': 53, 'EndOffset': 62, 'Score': 0.999940...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.9879459585199664, 'Text': 'section one'}, {'BeginOffset': 34, 'EndOffset': 46, 'Score': 0.9997940...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                              KeyPhrases  \\\n",
       "0  [{'BeginOffset': 26, 'EndOffset': 33, 'Score': 0.8727456819495607, 'Text': 'academy'}, {'BeginOffset': 37, 'EndOffset': 65, 'Score': 0.75145980506...   \n",
       "1  [{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.6214939014751475, 'Text': 'module two'}, {'BeginOffset': 33, 'EndOffset': 52, 'Score': 0.99413129...   \n",
       "2  [{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.9589880415051381, 'Text': 'section three'}, {'BeginOffset': 72, 'EndOffset': 99, 'Score': 0.99856...   \n",
       "3  [{'BeginOffset': 17, 'EndOffset': 29, 'Score': 0.9997500325485067, 'Text': 'this section'}, {'BeginOffset': 53, 'EndOffset': 62, 'Score': 0.999940...   \n",
       "4  [{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.9879459585199664, 'Text': 'section one'}, {'BeginOffset': 34, 'EndOffset': 46, 'Score': 0.9997940...   \n",
       "\n",
       "   Line  \n",
       "0     0  \n",
       "1     1  \n",
       "2     4  \n",
       "3     5  \n",
       "4     2  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpdf = pd.DataFrame(data, columns=['KeyPhrases','Line'])\n",
    "kpdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = []\n",
    "with open ('entity_output', \"r\") as myfile:\n",
    "    for line in myfile:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 546, 'EndOff...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.8810036668646961, 'Text': 'module two', 'Type': 'OTHER'}, {'BeginOffset': 33, 'EndOffset': 36, 'S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.6055191654832432, 'Text': 'section three', 'Type': 'OTHER'}, {'BeginOffset': 460, 'EndOffset': 46...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'BeginOffset': 169, 'EndOffset': 182, 'Score': 0.5567611517410612, 'Text': 'all the tools', 'Type': 'QUANTITY'}, {'BeginOffset': 193, 'EndOffset...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.8874841148902434, 'Text': 'section one', 'Type': 'OTHER'}, {'BeginOffset': 183, 'EndOffset': 188,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                Entities  \\\n",
       "0  [{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 546, 'EndOff...   \n",
       "1  [{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.8810036668646961, 'Text': 'module two', 'Type': 'OTHER'}, {'BeginOffset': 33, 'EndOffset': 36, 'S...   \n",
       "2  [{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.6055191654832432, 'Text': 'section three', 'Type': 'OTHER'}, {'BeginOffset': 460, 'EndOffset': 46...   \n",
       "3  [{'BeginOffset': 169, 'EndOffset': 182, 'Score': 0.5567611517410612, 'Text': 'all the tools', 'Type': 'QUANTITY'}, {'BeginOffset': 193, 'EndOffset...   \n",
       "4  [{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.8874841148902434, 'Text': 'section one', 'Type': 'OTHER'}, {'BeginOffset': 183, 'EndOffset': 188,...   \n",
       "\n",
       "   Line  \n",
       "0     0  \n",
       "1     1  \n",
       "2     4  \n",
       "3     5  \n",
       "4     2  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitydf = pd.DataFrame(data, columns=['Entities','Line'])\n",
    "entitydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(entities, entity_type):\n",
    "    filtered_entities=[]\n",
    "    for entity in entities:\n",
    "        if entity['Type'] == entity_type:\n",
    "            filtered_entities.append(entity)\n",
    "    return filtered_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Line</th>\n",
       "      <th>location</th>\n",
       "      <th>organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 546, 'EndOff...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 561, 'EndOff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.8810036668646961, 'Text': 'module two', 'Type': 'OTHER'}, {'BeginOffset': 33, 'EndOffset': 36, 'S...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'BeginOffset': 33, 'EndOffset': 36, 'Score': 0.9779731824490148, 'Text': 'aws', 'Type': 'ORGANIZATION'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.6055191654832432, 'Text': 'section three', 'Type': 'OTHER'}, {'BeginOffset': 460, 'EndOffset': 46...</td>\n",
       "      <td>4</td>\n",
       "      <td>[{'BeginOffset': 3626, 'EndOffset': 3628, 'Score': 0.8398416469737435, 'Text': 'uk', 'Type': 'LOCATION'}]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'BeginOffset': 169, 'EndOffset': 182, 'Score': 0.5567611517410612, 'Text': 'all the tools', 'Type': 'QUANTITY'}, {'BeginOffset': 193, 'EndOffset...</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'BeginOffset': 307, 'EndOffset': 314, 'Score': 0.6630072743677669, 'Text': 'jupiter', 'Type': 'ORGANIZATION'}, {'BeginOffset': 329, 'EndOffset':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.8874841148902434, 'Text': 'section one', 'Type': 'OTHER'}, {'BeginOffset': 183, 'EndOffset': 188,...</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                Entities  \\\n",
       "0  [{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 546, 'EndOff...   \n",
       "1  [{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.8810036668646961, 'Text': 'module two', 'Type': 'OTHER'}, {'BeginOffset': 33, 'EndOffset': 36, 'S...   \n",
       "2  [{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.6055191654832432, 'Text': 'section three', 'Type': 'OTHER'}, {'BeginOffset': 460, 'EndOffset': 46...   \n",
       "3  [{'BeginOffset': 169, 'EndOffset': 182, 'Score': 0.5567611517410612, 'Text': 'all the tools', 'Type': 'QUANTITY'}, {'BeginOffset': 193, 'EndOffset...   \n",
       "4  [{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.8874841148902434, 'Text': 'section one', 'Type': 'OTHER'}, {'BeginOffset': 183, 'EndOffset': 188,...   \n",
       "\n",
       "   Line  \\\n",
       "0     0   \n",
       "1     1   \n",
       "2     4   \n",
       "3     5   \n",
       "4     2   \n",
       "\n",
       "                                                                                                    location  \\\n",
       "0                                                                                                         []   \n",
       "1                                                                                                         []   \n",
       "2  [{'BeginOffset': 3626, 'EndOffset': 3628, 'Score': 0.8398416469737435, 'Text': 'uk', 'Type': 'LOCATION'}]   \n",
       "3                                                                                                         []   \n",
       "4                                                                                                         []   \n",
       "\n",
       "                                                                                                                                            organization  \n",
       "0  [{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 561, 'EndOff...  \n",
       "1                                             [{'BeginOffset': 33, 'EndOffset': 36, 'Score': 0.9779731824490148, 'Text': 'aws', 'Type': 'ORGANIZATION'}]  \n",
       "2                                                                                                                                                     []  \n",
       "3  [{'BeginOffset': 307, 'EndOffset': 314, 'Score': 0.6630072743677669, 'Text': 'jupiter', 'Type': 'ORGANIZATION'}, {'BeginOffset': 329, 'EndOffset':...  \n",
       "4                                                                                                                                                     []  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['plot_normalized'] = df['plot'].apply(normalize_text)    \n",
    "entitydf['location'] = entitydf['Entities'].apply(lambda x: extract_entities(x, 'LOCATION'))\n",
    "entitydf['organization'] = entitydf['Entities'].apply(lambda x: extract_entities(x, 'ORGANIZATION'))\n",
    "\n",
    "entitydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>location</th>\n",
       "      <th>organization</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Line</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 546, 'EndOff...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 561, 'EndOff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.8810036668646961, 'Text': 'module two', 'Type': 'OTHER'}, {'BeginOffset': 33, 'EndOffset': 36, 'S...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'BeginOffset': 33, 'EndOffset': 36, 'Score': 0.9779731824490148, 'Text': 'aws', 'Type': 'ORGANIZATION'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.8874841148902434, 'Text': 'section one', 'Type': 'OTHER'}, {'BeginOffset': 183, 'EndOffset': 188,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'BeginOffset': 763, 'EndOffset': 767, 'Score': 0.5536403180912558, 'Text': 'more', 'Type': 'QUANTITY'}, {'BeginOffset': 935, 'EndOffset': 951, '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.6055191654832432, 'Text': 'section three', 'Type': 'OTHER'}, {'BeginOffset': 460, 'EndOffset': 46...</td>\n",
       "      <td>[{'BeginOffset': 3626, 'EndOffset': 3628, 'Score': 0.8398416469737435, 'Text': 'uk', 'Type': 'LOCATION'}]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                   Entities  \\\n",
       "Line                                                                                                                                                          \n",
       "0     [{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 546, 'EndOff...   \n",
       "1     [{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.8810036668646961, 'Text': 'module two', 'Type': 'OTHER'}, {'BeginOffset': 33, 'EndOffset': 36, 'S...   \n",
       "2     [{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.8874841148902434, 'Text': 'section one', 'Type': 'OTHER'}, {'BeginOffset': 183, 'EndOffset': 188,...   \n",
       "3     [{'BeginOffset': 763, 'EndOffset': 767, 'Score': 0.5536403180912558, 'Text': 'more', 'Type': 'QUANTITY'}, {'BeginOffset': 935, 'EndOffset': 951, '...   \n",
       "4     [{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.6055191654832432, 'Text': 'section three', 'Type': 'OTHER'}, {'BeginOffset': 460, 'EndOffset': 46...   \n",
       "\n",
       "                                                                                                       location  \\\n",
       "Line                                                                                                              \n",
       "0                                                                                                            []   \n",
       "1                                                                                                            []   \n",
       "2                                                                                                            []   \n",
       "3                                                                                                            []   \n",
       "4     [{'BeginOffset': 3626, 'EndOffset': 3628, 'Score': 0.8398416469737435, 'Text': 'uk', 'Type': 'LOCATION'}]   \n",
       "\n",
       "                                                                                                                                               organization  \n",
       "Line                                                                                                                                                         \n",
       "0     [{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 561, 'EndOff...  \n",
       "1                                                [{'BeginOffset': 33, 'EndOffset': 36, 'Score': 0.9779731824490148, 'Text': 'aws', 'Type': 'ORGANIZATION'}]  \n",
       "2                                                                                                                                                        []  \n",
       "3                                                                                                                                                        []  \n",
       "4                                                                                                                                                        []  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitydf.set_index('Line', inplace = True)\n",
    "entitydf.sort_index(inplace=True)\n",
    "kpdf.set_index('Line', inplace=True)\n",
    "kpdf.sort_index(inplace=True)\n",
    "entitydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KeyPhrases</th>\n",
       "      <th>Entities</th>\n",
       "      <th>location</th>\n",
       "      <th>organization</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Line</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'BeginOffset': 26, 'EndOffset': 33, 'Score': 0.8727456819495607, 'Text': 'academy'}, {'BeginOffset': 37, 'EndOffset': 65, 'Score': 0.7514598050663223, 'Text': 'machine learning foundations'}, {'...</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 546, 'EndOffset': 551, 'Score': 0.951490867966341, 'Text': 'fi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 561, 'EndOffset': 572, 'Score': 0.9064068657229468, 'Text': 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.6214939014751475, 'Text': 'module two'}, {'BeginOffset': 33, 'EndOffset': 52, 'Score': 0.9941312955832783, 'Text': 'aws academy machine'}, {'BeginO...</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.8810036668646961, 'Text': 'module two', 'Type': 'OTHER'}, {'BeginOffset': 33, 'EndOffset': 36, 'Score': 0.9779731824490148, 'Text': 'aws', 'Type': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'BeginOffset': 33, 'EndOffset': 36, 'Score': 0.9779731824490148, 'Text': 'aws', 'Type': 'ORGANIZATION'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.9879459585199664, 'Text': 'section one'}, {'BeginOffset': 34, 'EndOffset': 46, 'Score': 0.9997940602015712, 'Text': 'this section'}, {'BeginOffset'...</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.8874841148902434, 'Text': 'section one', 'Type': 'OTHER'}, {'BeginOffset': 183, 'EndOffset': 188, 'Score': 0.9281728391309813, 'Text': 'first', 'Ty...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'BeginOffset': 24, 'EndOffset': 36, 'Score': 0.9996331597282907, 'Text': 'this section'}, {'BeginOffset': 61, 'EndOffset': 70, 'Score': 0.999921626630556, 'Text': 'the types'}, {'BeginOffset': 7...</td>\n",
       "      <td>[{'BeginOffset': 763, 'EndOffset': 767, 'Score': 0.5536403180912558, 'Text': 'more', 'Type': 'QUANTITY'}, {'BeginOffset': 935, 'EndOffset': 951, 'Score': 0.9698888667844483, 'Text': 'three main ty...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.9589880415051381, 'Text': 'section three'}, {'BeginOffset': 72, 'EndOffset': 99, 'Score': 0.9985641596345158, 'Text': 'a quick high level overview'...</td>\n",
       "      <td>[{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.6055191654832432, 'Text': 'section three', 'Type': 'OTHER'}, {'BeginOffset': 460, 'EndOffset': 468, 'Score': 0.9755549403380089, 'Text': 'one task'...</td>\n",
       "      <td>[{'BeginOffset': 3626, 'EndOffset': 3628, 'Score': 0.8398416469737435, 'Text': 'uk', 'Type': 'LOCATION'}]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                   KeyPhrases  \\\n",
       "Line                                                                                                                                                                                                            \n",
       "0     [{'BeginOffset': 26, 'EndOffset': 33, 'Score': 0.8727456819495607, 'Text': 'academy'}, {'BeginOffset': 37, 'EndOffset': 65, 'Score': 0.7514598050663223, 'Text': 'machine learning foundations'}, {'...   \n",
       "1     [{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.6214939014751475, 'Text': 'module two'}, {'BeginOffset': 33, 'EndOffset': 52, 'Score': 0.9941312955832783, 'Text': 'aws academy machine'}, {'BeginO...   \n",
       "2     [{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.9879459585199664, 'Text': 'section one'}, {'BeginOffset': 34, 'EndOffset': 46, 'Score': 0.9997940602015712, 'Text': 'this section'}, {'BeginOffset'...   \n",
       "3     [{'BeginOffset': 24, 'EndOffset': 36, 'Score': 0.9996331597282907, 'Text': 'this section'}, {'BeginOffset': 61, 'EndOffset': 70, 'Score': 0.999921626630556, 'Text': 'the types'}, {'BeginOffset': 7...   \n",
       "4     [{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.9589880415051381, 'Text': 'section three'}, {'BeginOffset': 72, 'EndOffset': 99, 'Score': 0.9985641596345158, 'Text': 'a quick high level overview'...   \n",
       "\n",
       "                                                                                                                                                                                                     Entities  \\\n",
       "Line                                                                                                                                                                                                            \n",
       "0     [{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 546, 'EndOffset': 551, 'Score': 0.951490867966341, 'Text': 'fi...   \n",
       "1     [{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.8810036668646961, 'Text': 'module two', 'Type': 'OTHER'}, {'BeginOffset': 33, 'EndOffset': 36, 'Score': 0.9779731824490148, 'Text': 'aws', 'Type': ...   \n",
       "2     [{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.8874841148902434, 'Text': 'section one', 'Type': 'OTHER'}, {'BeginOffset': 183, 'EndOffset': 188, 'Score': 0.9281728391309813, 'Text': 'first', 'Ty...   \n",
       "3     [{'BeginOffset': 763, 'EndOffset': 767, 'Score': 0.5536403180912558, 'Text': 'more', 'Type': 'QUANTITY'}, {'BeginOffset': 935, 'EndOffset': 951, 'Score': 0.9698888667844483, 'Text': 'three main ty...   \n",
       "4     [{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.6055191654832432, 'Text': 'section three', 'Type': 'OTHER'}, {'BeginOffset': 460, 'EndOffset': 468, 'Score': 0.9755549403380089, 'Text': 'one task'...   \n",
       "\n",
       "                                                                                                       location  \\\n",
       "Line                                                                                                              \n",
       "0                                                                                                            []   \n",
       "1                                                                                                            []   \n",
       "2                                                                                                            []   \n",
       "3                                                                                                            []   \n",
       "4     [{'BeginOffset': 3626, 'EndOffset': 3628, 'Score': 0.8398416469737435, 'Text': 'uk', 'Type': 'LOCATION'}]   \n",
       "\n",
       "                                                                                                                                                                                                 organization  \n",
       "Line                                                                                                                                                                                                           \n",
       "0     [{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 561, 'EndOffset': 572, 'Score': 0.9064068657229468, 'Text': 'a...  \n",
       "1                                                                                                  [{'BeginOffset': 33, 'EndOffset': 36, 'Score': 0.9779731824490148, 'Text': 'aws', 'Type': 'ORGANIZATION'}]  \n",
       "2                                                                                                                                                                                                          []  \n",
       "3                                                                                                                                                                                                          []  \n",
       "4                                                                                                                                                                                                          []  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = kpdf.merge(entitydf, left_index=True, right_index=True)\n",
    "m1.sort_index(inplace=True)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "m1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedDf = df.merge(m1, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OutputFile</th>\n",
       "      <th>Video</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>Transcription_normalized</th>\n",
       "      <th>KeyPhrases</th>\n",
       "      <th>Entities</th>\n",
       "      <th>location</th>\n",
       "      <th>organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transcribed-input/Mod01_Course_Overview.txt</td>\n",
       "      <td>input/Mod01_Course Overview.mp4</td>\n",
       "      <td>Hi and welcome to Amazon Academy of Machine Learning Foundations in this module, you'll learn about the course objectives, various job roles in the machine learning domain and where you can go to ...</td>\n",
       "      <td>hi and welcome to amazon academy of machine learning foundations in this module, you'll learn about the course objectives, various job roles in the machine learning domain and where you can go to ...</td>\n",
       "      <td>[{'BeginOffset': 26, 'EndOffset': 33, 'Score': 0.8727456819495607, 'Text': 'academy'}, {'BeginOffset': 37, 'EndOffset': 65, 'Score': 0.7514598050663223, 'Text': 'machine learning foundations'}, {'...</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 546, 'EndOffset': 551, 'Score': 0.951490867966341, 'Text': 'fi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 561, 'EndOffset': 572, 'Score': 0.9064068657229468, 'Text': 'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transcribed-input/Mod02_Intro.txt</td>\n",
       "      <td>input/Mod02_Intro.mp4</td>\n",
       "      <td>Hi and welcome to module two of Aws Academy machine learning in this module, we're going to introduce machine learning. We'll first look at the business problems that can be solved by machine lear...</td>\n",
       "      <td>hi and welcome to module two of aws academy machine learning in this module, we're going to introduce machine learning. we'll first look at the business problems that can be solved by machine lear...</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.6214939014751475, 'Text': 'module two'}, {'BeginOffset': 33, 'EndOffset': 52, 'Score': 0.9941312955832783, 'Text': 'aws academy machine'}, {'BeginO...</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.8810036668646961, 'Text': 'module two', 'Type': 'OTHER'}, {'BeginOffset': 33, 'EndOffset': 36, 'Score': 0.9779731824490148, 'Text': 'aws', 'Type': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'BeginOffset': 33, 'EndOffset': 36, 'Score': 0.9779731824490148, 'Text': 'aws', 'Type': 'ORGANIZATION'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transcribed-input/Mod02_Sect01.txt</td>\n",
       "      <td>input/Mod02_Sect01.mp4</td>\n",
       "      <td>Hi and welcome to section one in this section. We're going to talk about what machine learning is. This course is an introduction to machine learning, which is also known as ML. But first we'll di...</td>\n",
       "      <td>hi and welcome to section one in this section. we're going to talk about what machine learning is. this course is an introduction to machine learning, which is also known as ml. but first we'll di...</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.9879459585199664, 'Text': 'section one'}, {'BeginOffset': 34, 'EndOffset': 46, 'Score': 0.9997940602015712, 'Text': 'this section'}, {'BeginOffset'...</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.8874841148902434, 'Text': 'section one', 'Type': 'OTHER'}, {'BeginOffset': 183, 'EndOffset': 188, 'Score': 0.9281728391309813, 'Text': 'first', 'Ty...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transcribed-input/Mod02_Sect02.txt</td>\n",
       "      <td>input/Mod02_Sect02.mp4</td>\n",
       "      <td>Hi and welcome back in this section. We're going to look at the types of business problems. Machine learning can help you solve. Machine learning is used all across your digital lives. Your email ...</td>\n",
       "      <td>hi and welcome back in this section. we're going to look at the types of business problems. machine learning can help you solve. machine learning is used all across your digital lives. your email ...</td>\n",
       "      <td>[{'BeginOffset': 24, 'EndOffset': 36, 'Score': 0.9996331597282907, 'Text': 'this section'}, {'BeginOffset': 61, 'EndOffset': 70, 'Score': 0.999921626630556, 'Text': 'the types'}, {'BeginOffset': 7...</td>\n",
       "      <td>[{'BeginOffset': 763, 'EndOffset': 767, 'Score': 0.5536403180912558, 'Text': 'more', 'Type': 'QUANTITY'}, {'BeginOffset': 935, 'EndOffset': 951, 'Score': 0.9698888667844483, 'Text': 'three main ty...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transcribed-input/Mod02_Sect03.txt</td>\n",
       "      <td>input/Mod02_Sect03.mp4</td>\n",
       "      <td>Hi and welcome back. This is section three and we're going to give you a quick high level overview of machine learning terminology and a typical workflow. We will cover these topics in more detail...</td>\n",
       "      <td>hi and welcome back. this is section three and we're going to give you a quick high level overview of machine learning terminology and a typical workflow. we will cover these topics in more detail...</td>\n",
       "      <td>[{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.9589880415051381, 'Text': 'section three'}, {'BeginOffset': 72, 'EndOffset': 99, 'Score': 0.9985641596345158, 'Text': 'a quick high level overview'...</td>\n",
       "      <td>[{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.6055191654832432, 'Text': 'section three', 'Type': 'OTHER'}, {'BeginOffset': 460, 'EndOffset': 468, 'Score': 0.9755549403380089, 'Text': 'one task'...</td>\n",
       "      <td>[{'BeginOffset': 3626, 'EndOffset': 3628, 'Score': 0.8398416469737435, 'Text': 'uk', 'Type': 'LOCATION'}]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    OutputFile  \\\n",
       "0  transcribed-input/Mod01_Course_Overview.txt   \n",
       "1            transcribed-input/Mod02_Intro.txt   \n",
       "2           transcribed-input/Mod02_Sect01.txt   \n",
       "3           transcribed-input/Mod02_Sect02.txt   \n",
       "4           transcribed-input/Mod02_Sect03.txt   \n",
       "\n",
       "                             Video  \\\n",
       "0  input/Mod01_Course Overview.mp4   \n",
       "1            input/Mod02_Intro.mp4   \n",
       "2           input/Mod02_Sect01.mp4   \n",
       "3           input/Mod02_Sect02.mp4   \n",
       "4           input/Mod02_Sect03.mp4   \n",
       "\n",
       "                                                                                                                                                                                             Transcription  \\\n",
       "0  Hi and welcome to Amazon Academy of Machine Learning Foundations in this module, you'll learn about the course objectives, various job roles in the machine learning domain and where you can go to ...   \n",
       "1  Hi and welcome to module two of Aws Academy machine learning in this module, we're going to introduce machine learning. We'll first look at the business problems that can be solved by machine lear...   \n",
       "2  Hi and welcome to section one in this section. We're going to talk about what machine learning is. This course is an introduction to machine learning, which is also known as ML. But first we'll di...   \n",
       "3  Hi and welcome back in this section. We're going to look at the types of business problems. Machine learning can help you solve. Machine learning is used all across your digital lives. Your email ...   \n",
       "4  Hi and welcome back. This is section three and we're going to give you a quick high level overview of machine learning terminology and a typical workflow. We will cover these topics in more detail...   \n",
       "\n",
       "                                                                                                                                                                                  Transcription_normalized  \\\n",
       "0  hi and welcome to amazon academy of machine learning foundations in this module, you'll learn about the course objectives, various job roles in the machine learning domain and where you can go to ...   \n",
       "1  hi and welcome to module two of aws academy machine learning in this module, we're going to introduce machine learning. we'll first look at the business problems that can be solved by machine lear...   \n",
       "2  hi and welcome to section one in this section. we're going to talk about what machine learning is. this course is an introduction to machine learning, which is also known as ml. but first we'll di...   \n",
       "3  hi and welcome back in this section. we're going to look at the types of business problems. machine learning can help you solve. machine learning is used all across your digital lives. your email ...   \n",
       "4  hi and welcome back. this is section three and we're going to give you a quick high level overview of machine learning terminology and a typical workflow. we will cover these topics in more detail...   \n",
       "\n",
       "                                                                                                                                                                                                KeyPhrases  \\\n",
       "0  [{'BeginOffset': 26, 'EndOffset': 33, 'Score': 0.8727456819495607, 'Text': 'academy'}, {'BeginOffset': 37, 'EndOffset': 65, 'Score': 0.7514598050663223, 'Text': 'machine learning foundations'}, {'...   \n",
       "1  [{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.6214939014751475, 'Text': 'module two'}, {'BeginOffset': 33, 'EndOffset': 52, 'Score': 0.9941312955832783, 'Text': 'aws academy machine'}, {'BeginO...   \n",
       "2  [{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.9879459585199664, 'Text': 'section one'}, {'BeginOffset': 34, 'EndOffset': 46, 'Score': 0.9997940602015712, 'Text': 'this section'}, {'BeginOffset'...   \n",
       "3  [{'BeginOffset': 24, 'EndOffset': 36, 'Score': 0.9996331597282907, 'Text': 'this section'}, {'BeginOffset': 61, 'EndOffset': 70, 'Score': 0.999921626630556, 'Text': 'the types'}, {'BeginOffset': 7...   \n",
       "4  [{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.9589880415051381, 'Text': 'section three'}, {'BeginOffset': 72, 'EndOffset': 99, 'Score': 0.9985641596345158, 'Text': 'a quick high level overview'...   \n",
       "\n",
       "                                                                                                                                                                                                  Entities  \\\n",
       "0  [{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 546, 'EndOffset': 551, 'Score': 0.951490867966341, 'Text': 'fi...   \n",
       "1  [{'BeginOffset': 19, 'EndOffset': 29, 'Score': 0.8810036668646961, 'Text': 'module two', 'Type': 'OTHER'}, {'BeginOffset': 33, 'EndOffset': 36, 'Score': 0.9779731824490148, 'Text': 'aws', 'Type': ...   \n",
       "2  [{'BeginOffset': 19, 'EndOffset': 30, 'Score': 0.8874841148902434, 'Text': 'section one', 'Type': 'OTHER'}, {'BeginOffset': 183, 'EndOffset': 188, 'Score': 0.9281728391309813, 'Text': 'first', 'Ty...   \n",
       "3  [{'BeginOffset': 763, 'EndOffset': 767, 'Score': 0.5536403180912558, 'Text': 'more', 'Type': 'QUANTITY'}, {'BeginOffset': 935, 'EndOffset': 951, 'Score': 0.9698888667844483, 'Text': 'three main ty...   \n",
       "4  [{'BeginOffset': 30, 'EndOffset': 43, 'Score': 0.6055191654832432, 'Text': 'section three', 'Type': 'OTHER'}, {'BeginOffset': 460, 'EndOffset': 468, 'Score': 0.9755549403380089, 'Text': 'one task'...   \n",
       "\n",
       "                                                                                                    location  \\\n",
       "0                                                                                                         []   \n",
       "1                                                                                                         []   \n",
       "2                                                                                                         []   \n",
       "3                                                                                                         []   \n",
       "4  [{'BeginOffset': 3626, 'EndOffset': 3628, 'Score': 0.8398416469737435, 'Text': 'uk', 'Type': 'LOCATION'}]   \n",
       "\n",
       "                                                                                                                                                                                              organization  \n",
       "0  [{'BeginOffset': 19, 'EndOffset': 33, 'Score': 0.9060990005037325, 'Text': 'amazon academy', 'Type': 'ORGANIZATION'}, {'BeginOffset': 561, 'EndOffset': 572, 'Score': 0.9064068657229468, 'Text': 'a...  \n",
       "1                                                                                               [{'BeginOffset': 33, 'EndOffset': 36, 'Score': 0.9779731824490148, 'Text': 'aws', 'Type': 'ORGANIZATION'}]  \n",
       "2                                                                                                                                                                                                       []  \n",
       "3                                                                                                                                                                                                       []  \n",
       "4                                                                                                                                                                                                       []  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OutputFile</th>\n",
       "      <th>Video</th>\n",
       "      <th>Transcription</th>\n",
       "      <th>Transcription_normalized</th>\n",
       "      <th>KeyPhrases</th>\n",
       "      <th>Entities</th>\n",
       "      <th>location</th>\n",
       "      <th>organization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>transcribed-input/Mod01_Course_Overview.txt</td>\n",
       "      <td>input/Mod01_Course Overview.mp4</td>\n",
       "      <td>Hi and welcome to Amazon Academy of Machine Le...</td>\n",
       "      <td>hi and welcome to amazon academy of machine le...</td>\n",
       "      <td>[{'BeginOffset': 26, 'EndOffset': 33, 'Score':...</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 33, 'Score':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 33, 'Score':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>transcribed-input/Mod02_Intro.txt</td>\n",
       "      <td>input/Mod02_Intro.mp4</td>\n",
       "      <td>Hi and welcome to module two of Aws Academy ma...</td>\n",
       "      <td>hi and welcome to module two of aws academy ma...</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 29, 'Score':...</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 29, 'Score':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'BeginOffset': 33, 'EndOffset': 36, 'Score':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>transcribed-input/Mod02_Sect01.txt</td>\n",
       "      <td>input/Mod02_Sect01.mp4</td>\n",
       "      <td>Hi and welcome to section one in this section....</td>\n",
       "      <td>hi and welcome to section one in this section....</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 30, 'Score':...</td>\n",
       "      <td>[{'BeginOffset': 19, 'EndOffset': 30, 'Score':...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transcribed-input/Mod02_Sect02.txt</td>\n",
       "      <td>input/Mod02_Sect02.mp4</td>\n",
       "      <td>Hi and welcome back in this section. We're goi...</td>\n",
       "      <td>hi and welcome back in this section. we're goi...</td>\n",
       "      <td>[{'BeginOffset': 24, 'EndOffset': 36, 'Score':...</td>\n",
       "      <td>[{'BeginOffset': 763, 'EndOffset': 767, 'Score...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transcribed-input/Mod02_Sect03.txt</td>\n",
       "      <td>input/Mod02_Sect03.mp4</td>\n",
       "      <td>Hi and welcome back. This is section three and...</td>\n",
       "      <td>hi and welcome back. this is section three and...</td>\n",
       "      <td>[{'BeginOffset': 30, 'EndOffset': 43, 'Score':...</td>\n",
       "      <td>[{'BeginOffset': 30, 'EndOffset': 43, 'Score':...</td>\n",
       "      <td>[{'BeginOffset': 3626, 'EndOffset': 3628, 'Sco...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    OutputFile  \\\n",
       "0  transcribed-input/Mod01_Course_Overview.txt   \n",
       "1            transcribed-input/Mod02_Intro.txt   \n",
       "2           transcribed-input/Mod02_Sect01.txt   \n",
       "3           transcribed-input/Mod02_Sect02.txt   \n",
       "4           transcribed-input/Mod02_Sect03.txt   \n",
       "\n",
       "                             Video  \\\n",
       "0  input/Mod01_Course Overview.mp4   \n",
       "1            input/Mod02_Intro.mp4   \n",
       "2           input/Mod02_Sect01.mp4   \n",
       "3           input/Mod02_Sect02.mp4   \n",
       "4           input/Mod02_Sect03.mp4   \n",
       "\n",
       "                                       Transcription  \\\n",
       "0  Hi and welcome to Amazon Academy of Machine Le...   \n",
       "1  Hi and welcome to module two of Aws Academy ma...   \n",
       "2  Hi and welcome to section one in this section....   \n",
       "3  Hi and welcome back in this section. We're goi...   \n",
       "4  Hi and welcome back. This is section three and...   \n",
       "\n",
       "                            Transcription_normalized  \\\n",
       "0  hi and welcome to amazon academy of machine le...   \n",
       "1  hi and welcome to module two of aws academy ma...   \n",
       "2  hi and welcome to section one in this section....   \n",
       "3  hi and welcome back in this section. we're goi...   \n",
       "4  hi and welcome back. this is section three and...   \n",
       "\n",
       "                                          KeyPhrases  \\\n",
       "0  [{'BeginOffset': 26, 'EndOffset': 33, 'Score':...   \n",
       "1  [{'BeginOffset': 19, 'EndOffset': 29, 'Score':...   \n",
       "2  [{'BeginOffset': 19, 'EndOffset': 30, 'Score':...   \n",
       "3  [{'BeginOffset': 24, 'EndOffset': 36, 'Score':...   \n",
       "4  [{'BeginOffset': 30, 'EndOffset': 43, 'Score':...   \n",
       "\n",
       "                                            Entities  \\\n",
       "0  [{'BeginOffset': 19, 'EndOffset': 33, 'Score':...   \n",
       "1  [{'BeginOffset': 19, 'EndOffset': 29, 'Score':...   \n",
       "2  [{'BeginOffset': 19, 'EndOffset': 30, 'Score':...   \n",
       "3  [{'BeginOffset': 763, 'EndOffset': 767, 'Score...   \n",
       "4  [{'BeginOffset': 30, 'EndOffset': 43, 'Score':...   \n",
       "\n",
       "                                            location  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [{'BeginOffset': 3626, 'EndOffset': 3628, 'Sco...   \n",
       "\n",
       "                                        organization  \n",
       "0  [{'BeginOffset': 19, 'EndOffset': 33, 'Score':...  \n",
       "1  [{'BeginOffset': 33, 'EndOffset': 36, 'Score':...  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 50)\n",
    "mergedDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................ready!\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "alive = es_client.describe_elasticsearch_domain(DomainName='nlp-lab')\n",
    "while alive['DomainStatus']['Processing']:\n",
    "    print('.', end='')\n",
    "    sleep(10)\n",
    "    alive = es_client.describe_elasticsearch_domain(DomainName='nlp-lab')\n",
    "    \n",
    "print('ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(60)\n",
    "es_domain = es_client.describe_elasticsearch_domain(DomainName='nlp-lab')\n",
    "es_endpoint = es_domain['DomainStatus']['Endpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "region= 'us-east-1' \n",
    "service = 'es' \n",
    "credentials = boto3.Session().get_credentials()\n",
    "\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
    "es = OpenSearch(\n",
    "    hosts = [{'host': es_endpoint, 'port': 443}],\n",
    "    http_auth = awsauth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'input/Mod02_Sect02.mp4', 'transcription': \"Hi and welcome back in this section. We're going to look at the types of business problems. Machine learning can help you solve. Machine learning is used all across your digital lives. Your email spam filter is the result of a machine learning program that was trained with examples of spam and regular email messages based on books. You're reading or products you bought machine learning programs can predict other books or products you're likely to be interested in. Again, the machine learning program was trained with data from other readers habits and purchases. When detecting credit card fraud, the machine learning program was trained on examples of transactions that turned out to be fraud along with normal transactions. You can probably think of many more examples from social media applications using facial detection to group your photos to detecting brain tumors in brain scans or finding anomalies in x rays. There are three main types of machine learning. There's supervised learning where a model uses known inputs and outputs to generalize future outputs. There's unsupervised learning where the model doesn't know inputs or outputs. So it finds patterns in the data without help. And there's reinforcement learning where the model interacts with its environment and learns to take actions that will maximize rewards. It's important to know the different types of ML because the type will guide you towards selecting algorithms that make sense for solving your business problem. Let's look more into each of these types. Supervised learning is a popular type of ML because it's widely applicable, it's called supervised learning because there needs to be a supervisor, a teacher who can show the right answers, so to speak. Like any student, a supervised algorithm needs to learn. By example, essentially it needs a teacher who uses training data to help it determine the patterns and relationships between the inputs and outputs. If you want to build an application to detect credit card fraud, you'd need training data that includes examples of fraud and examples of normal transactions within supervised learning. There are different types of problems, classification and regression. There are two subtypes of classification problems. The first is binary classification. Think back to the example with identifying fraudulent transactions. The target variable in this example is limited to two options, fraudulent or not fraudulent. This is a binary classification problem. There are also multi class classification problems. These ML problems classify an observation into one of three or more categories, say that you have an ML model that predicts why a customer is calling your store. So you can reduce the number of transfers needed before the customer gets to the correct customer support department. In this case, the different customer support departments represent the variety of potential target variables which could be many different departments much more than just two. There are also regression problems in a regression problem. You're no longer mapping an input to a defined number of categories. Instead you're mapping an input to a continuous value like an integer. One example of an ML regression problem is predicting the price of a company's stock. Computer vision is a good example of supervised learning. Is this a cat or a dog? Is there a tumor in this x-ray computer vision is often built with deep learning models. It automates the extraction analysis, classification and understanding of useful information from a single image or a sequence of images. Computer vision enables machines to identify people, places and things and images with accuracy at or above human levels and with greater speed and efficiency. The image data can take many forms such as single images, video sequences, views from multiple cameras or three dimensional data. You'll learn more about computer vision later. In this course, we'll now discuss unsupervised machine learning. Sometimes all you have is the data. There's no supervisor in the room in unsupervised learning labels aren't provided like they are with supervised learning. You don't know all the variables and patterns in these instances. The machine has to uncover and create the labels itself. These models use the data they're presented with to detect emerging properties of the entire data set, then they construct patterns from those properties. Clustering is a common subcategory of unsupervised learning. This kind of algorithm groups data into different clusters based on similar features. It does this to better understand the attributes of a specific cluster. For example, by analyzing customer purchasing habits, unsupervised algorithms can identify groups of customers that are associated with the size tier of a company. The advantage of unsupervised algorithms is that they enable you to see patterns in the data that you weren't aware of before natural language processing is also known as N LP. This is another area of machine learning that's experiencing growth. If you've ever used Alexa or any other voice assistant, they'll use N LP to try and answer your question. N LP isn't just about speech, it's also about written text. N LP shows up in many applications. For example, N LP is used with chat or call center bots which are automated systems that help you get your bank balance or order food from a restaurant. You can use N LP and translation tools which convert text between languages. For example, you might use applications that translate menus in real time. N LP is also used in voice to text translations which converts spoken words into text. And finally NLP can be used in sentiment analysis which you can use to analyze the sentiment of comments and reviews of products, music and movies. These sentiments could be used to give the movie an audience rating, you'll learn more about N LP later in this course. Another kind of machine learning that's been gaining popularity recently is reinforcement learning. Unlike other machine learning reinforcement learning continuously improves its model by mining feedback from previous iterations. In reinforcement learning, an agent continuously learns through trial and error as it interacts in an environment. Reinforcement learning is broadly useful when the reward of a desired outcome is known. But the path to achieving it isn't and that path requires a lot of trial and error to discover. Take the example of Aws Deep Racer in the Aws Deep Racer simulator. The agent is the virtual car. The environment is a virtual race track. The actions are throttle and steering inputs to the car. And the goal is completing the race track as quickly as possible. Without deviating from the track. The car needs to learn the desired driving behavior to reach the goal of completing the track for the car to learn this Aws Deep racer teams use rewards to incentivize their model to learn the desired driving behavior. In reinforcement learning the thing driving, the learning is called the agent. In this case, it's the AWS deep racer car. The environment is the place where the agent learns, which in this example would be the marked racetrack. When the agent does something in the environment that provokes a response such as crossing a boundary, it shouldn't cross, that's called an action that response is called a reward or penalty depending on whether the agent did something to be reinforced or discouraged. In the model. As the agent moves within the environment, its action should start receiving more rewards and fewer penalties until it meets the desired business outcome. Self driving vehicles, bring together many machine and deep learning algorithms and models to solve the problem of driving from point A to point B. Two of its main tasks are the continuous detection of the environment and forecasting changes. These involve detecting objects and localizing and predicting the movement of the detected objects. The outputs of these findings act as inputs to other systems that make decisions on what they should do with the vehicle's various controls. There are use cases in self driving vehicles that require real time responses to the environment. For example, if a previously hidden pedestrian walks out from behind an obstacle, the vehicle brakes need to be applied immediately, there can be no latency or room for error with these actions. Not every problem should be solved with machine learning. Sometimes regular programming will work well for your needs. If you're interested in exploring a potential machine learning solution, look for the existence of large data sets and a large number of variables. Machine learning is often the best choice if you're uncertain of the business logic or procedures needed to obtain an answer or accomplish a task. Machine learning systems can be complex. The supporting infrastructure management support and technical expertise need to be in place to help ensure the project's success. Here are the key takeaways for this section where we explored some machine learning applications that are already part of everyday life. First, machine learning problems can be grouped into three categories. Supervised learning is where you have training data where you already know the answer, unsupervised learning is where you have data but are looking for insights within the data reinforcement learning is where the model learns based on experience and feedback. Most business problems are supervised learning problems. Well, that's it for this section. We'll see you in the next video.\", 'keyphrases': [{'BeginOffset': 24, 'EndOffset': 36, 'Score': 0.9996331597282907, 'Text': 'this section'}, {'BeginOffset': 61, 'EndOffset': 70, 'Score': 0.999921626630556, 'Text': 'the types'}, {'BeginOffset': 74, 'EndOffset': 91, 'Score': 0.9967263828498905, 'Text': 'business problems'}, {'BeginOffset': 93, 'EndOffset': 109, 'Score': 0.9957156408842702, 'Text': 'machine learning'}, {'BeginOffset': 130, 'EndOffset': 146, 'Score': 0.9956345590473414, 'Text': 'machine learning'}, {'BeginOffset': 166, 'EndOffset': 184, 'Score': 0.9999054792172132, 'Text': 'your digital lives'}, {'BeginOffset': 186, 'EndOffset': 208, 'Score': 0.9984253858124604, 'Text': 'your email spam filter'}, {'BeginOffset': 212, 'EndOffset': 222, 'Score': 0.9999101848107042, 'Text': 'the result'}, {'BeginOffset': 226, 'EndOffset': 244, 'Score': 0.8110439557949295, 'Text': 'a machine learning'}, {'BeginOffset': 245, 'EndOffset': 252, 'Score': 0.7080841031374195, 'Text': 'program'}, {'BeginOffset': 275, 'EndOffset': 283, 'Score': 0.999898086446007, 'Text': 'examples'}, {'BeginOffset': 287, 'EndOffset': 291, 'Score': 0.9999408756865238, 'Text': 'spam'}, {'BeginOffset': 296, 'EndOffset': 318, 'Score': 0.8328285917566294, 'Text': 'regular email messages'}, {'BeginOffset': 328, 'EndOffset': 333, 'Score': 0.9999187058723578, 'Text': 'books'}, {'BeginOffset': 342, 'EndOffset': 349, 'Score': 0.5047988228251223, 'Text': 'reading'}, {'BeginOffset': 353, 'EndOffset': 361, 'Score': 0.6006750740812093, 'Text': 'products'}, {'BeginOffset': 373, 'EndOffset': 389, 'Score': 0.8174317166856087, 'Text': 'machine learning'}, {'BeginOffset': 390, 'EndOffset': 398, 'Score': 0.6880348272591014, 'Text': 'programs'}, {'BeginOffset': 411, 'EndOffset': 434, 'Score': 0.9975682355444748, 'Text': 'other books or products'}, {'BeginOffset': 477, 'EndOffset': 505, 'Score': 0.974313316551069, 'Text': 'the machine learning program'}, {'BeginOffset': 523, 'EndOffset': 527, 'Score': 0.999867099307243, 'Text': 'data'}, {'BeginOffset': 533, 'EndOffset': 567, 'Score': 0.9609193018566236, 'Text': 'other readers habits and purchases'}, {'BeginOffset': 584, 'EndOffset': 601, 'Score': 0.9977656385745808, 'Text': 'credit card fraud'}, {'BeginOffset': 603, 'EndOffset': 631, 'Score': 0.9281574304155338, 'Text': 'the machine learning program'}, {'BeginOffset': 647, 'EndOffset': 655, 'Score': 0.999911912093075, 'Text': 'examples'}, {'BeginOffset': 659, 'EndOffset': 671, 'Score': 0.9999800924450729, 'Text': 'transactions'}, {'BeginOffset': 694, 'EndOffset': 699, 'Score': 0.9671567565634945, 'Text': 'fraud'}, {'BeginOffset': 711, 'EndOffset': 730, 'Score': 0.9999451667363283, 'Text': 'normal transactions'}, {'BeginOffset': 758, 'EndOffset': 776, 'Score': 0.9983656342207914, 'Text': 'many more examples'}, {'BeginOffset': 782, 'EndOffset': 807, 'Score': 0.993515162786431, 'Text': 'social media applications'}, {'BeginOffset': 814, 'EndOffset': 830, 'Score': 0.9976414268565674, 'Text': 'facial detection'}, {'BeginOffset': 834, 'EndOffset': 839, 'Score': 0.9322801131601468, 'Text': 'group'}, {'BeginOffset': 840, 'EndOffset': 851, 'Score': 0.935803540582291, 'Text': 'your photos'}, {'BeginOffset': 865, 'EndOffset': 877, 'Score': 0.9990651227415344, 'Text': 'brain tumors'}, {'BeginOffset': 881, 'EndOffset': 892, 'Score': 0.9976420734740197, 'Text': 'brain scans'}, {'BeginOffset': 904, 'EndOffset': 913, 'Score': 0.7024100512060648, 'Text': 'anomalies'}, {'BeginOffset': 917, 'EndOffset': 923, 'Score': 0.9973434031478041, 'Text': 'x rays'}, {'BeginOffset': 935, 'EndOffset': 951, 'Score': 0.999867503973829, 'Text': 'three main types'}, {'BeginOffset': 955, 'EndOffset': 971, 'Score': 0.8705468243271747, 'Text': 'machine learning'}, {'BeginOffset': 1007, 'EndOffset': 1014, 'Score': 0.9999646557123755, 'Text': 'a model'}, {'BeginOffset': 1020, 'EndOffset': 1044, 'Score': 0.9985522942370656, 'Text': 'known inputs and outputs'}, {'BeginOffset': 1059, 'EndOffset': 1073, 'Score': 0.9966712105564268, 'Text': 'future outputs'}, {'BeginOffset': 1111, 'EndOffset': 1120, 'Score': 0.9999790196206895, 'Text': 'the model'}, {'BeginOffset': 1134, 'EndOffset': 1151, 'Score': 0.9996532012647295, 'Text': 'inputs or outputs'}, {'BeginOffset': 1165, 'EndOffset': 1173, 'Score': 0.9994782548833284, 'Text': 'patterns'}, {'BeginOffset': 1177, 'EndOffset': 1185, 'Score': 0.9999626890297247, 'Text': 'the data'}, {'BeginOffset': 1212, 'EndOffset': 1225, 'Score': 0.9361271261847776, 'Text': 'reinforcement'}, {'BeginOffset': 1241, 'EndOffset': 1250, 'Score': 0.9999638808887751, 'Text': 'the model'}, {'BeginOffset': 1266, 'EndOffset': 1281, 'Score': 0.9999805692692142, 'Text': 'its environment'}, {'BeginOffset': 1301, 'EndOffset': 1308, 'Score': 0.9999605432821229, 'Text': 'actions'}, {'BeginOffset': 1328, 'EndOffset': 1335, 'Score': 0.9971982282909261, 'Text': 'rewards'}, {'BeginOffset': 1360, 'EndOffset': 1379, 'Score': 0.9999109216222508, 'Text': 'the different types'}, {'BeginOffset': 1383, 'EndOffset': 1385, 'Score': 0.9965926084548541, 'Text': 'ml'}, {'BeginOffset': 1394, 'EndOffset': 1402, 'Score': 0.9999799136538133, 'Text': 'the type'}, {'BeginOffset': 1436, 'EndOffset': 1446, 'Score': 0.9937145124639346, 'Text': 'algorithms'}, {'BeginOffset': 1457, 'EndOffset': 1462, 'Score': 0.9986644961410622, 'Text': 'sense'}, {'BeginOffset': 1475, 'EndOffset': 1496, 'Score': 0.9996086511487797, 'Text': 'your business problem'}, {'BeginOffset': 1527, 'EndOffset': 1538, 'Score': 0.999905538324842, 'Text': 'these types'}, {'BeginOffset': 1540, 'EndOffset': 1559, 'Score': 0.8892718745417849, 'Text': 'supervised learning'}, {'BeginOffset': 1563, 'EndOffset': 1577, 'Score': 0.9999584374482156, 'Text': 'a popular type'}, {'BeginOffset': 1581, 'EndOffset': 1583, 'Score': 0.9982125579351282, 'Text': 'ml'}, {'BeginOffset': 1674, 'EndOffset': 1686, 'Score': 0.9999174546083852, 'Text': 'a supervisor'}, {'BeginOffset': 1688, 'EndOffset': 1697, 'Score': 0.9998868243439616, 'Text': 'a teacher'}, {'BeginOffset': 1711, 'EndOffset': 1728, 'Score': 0.9998222930861388, 'Text': 'the right answers'}, {'BeginOffset': 1748, 'EndOffset': 1759, 'Score': 0.9999289580834771, 'Text': 'any student'}, {'BeginOffset': 1761, 'EndOffset': 1783, 'Score': 0.9999403199206576, 'Text': 'a supervised algorithm'}, {'BeginOffset': 1833, 'EndOffset': 1842, 'Score': 0.9999489221189235, 'Text': 'a teacher'}, {'BeginOffset': 1852, 'EndOffset': 1865, 'Score': 0.9505085701964407, 'Text': 'training data'}, {'BeginOffset': 1887, 'EndOffset': 1917, 'Score': 0.9998717222284615, 'Text': 'the patterns and relationships'}, {'BeginOffset': 1926, 'EndOffset': 1948, 'Score': 0.9992212808197605, 'Text': 'the inputs and outputs'}, {'BeginOffset': 1971, 'EndOffset': 1985, 'Score': 0.9998482764573758, 'Text': 'an application'}, {'BeginOffset': 1996, 'EndOffset': 2013, 'Score': 0.9981262160881456, 'Text': 'credit card fraud'}, {'BeginOffset': 2026, 'EndOffset': 2039, 'Score': 0.9970036378036081, 'Text': 'training data'}, {'BeginOffset': 2054, 'EndOffset': 2062, 'Score': 0.9999114353416858, 'Text': 'examples'}, {'BeginOffset': 2066, 'EndOffset': 2084, 'Score': 0.9885473310452886, 'Text': 'fraud and examples'}, {'BeginOffset': 2088, 'EndOffset': 2107, 'Score': 0.9999345587316063, 'Text': 'normal transactions'}, {'BeginOffset': 2115, 'EndOffset': 2134, 'Score': 0.9134370876549177, 'Text': 'supervised learning'}, {'BeginOffset': 2146, 'EndOffset': 2161, 'Score': 0.999540409601511, 'Text': 'different types'}, {'BeginOffset': 2165, 'EndOffset': 2204, 'Score': 0.996813330626545, 'Text': 'problems, classification and regression'}, {'BeginOffset': 2216, 'EndOffset': 2228, 'Score': 0.999582406467664, 'Text': 'two subtypes'}, {'BeginOffset': 2232, 'EndOffset': 2255, 'Score': 0.9995264120227518, 'Text': 'classification problems'}, {'BeginOffset': 2257, 'EndOffset': 2266, 'Score': 0.9988354956502429, 'Text': 'the first'}, {'BeginOffset': 2270, 'EndOffset': 2291, 'Score': 0.9746413729532976, 'Text': 'binary classification'}, {'BeginOffset': 2307, 'EndOffset': 2318, 'Score': 0.9999257383241834, 'Text': 'the example'}, {'BeginOffset': 2336, 'EndOffset': 2359, 'Score': 0.9995607553525414, 'Text': 'fraudulent transactions'}, {'BeginOffset': 2361, 'EndOffset': 2380, 'Score': 0.999592737358552, 'Text': 'the target variable'}, {'BeginOffset': 2384, 'EndOffset': 2396, 'Score': 0.9999623315344028, 'Text': 'this example'}, {'BeginOffset': 2411, 'EndOffset': 2422, 'Score': 0.9859403647908584, 'Text': 'two options'}, {'BeginOffset': 2462, 'EndOffset': 2493, 'Score': 0.9990820443829859, 'Text': 'a binary classification problem'}, {'BeginOffset': 2510, 'EndOffset': 2545, 'Score': 0.9851845199916014, 'Text': 'multi class classification problems'}, {'BeginOffset': 2547, 'EndOffset': 2564, 'Score': 0.9917235325959699, 'Text': 'these ml problems'}, {'BeginOffset': 2574, 'EndOffset': 2588, 'Score': 0.9997890477862117, 'Text': 'an observation'}, {'BeginOffset': 2601, 'EndOffset': 2625, 'Score': 0.9884909436761894, 'Text': 'three or more categories'}, {'BeginOffset': 2645, 'EndOffset': 2656, 'Score': 0.9997046218571497, 'Text': 'an ml model'}, {'BeginOffset': 2675, 'EndOffset': 2685, 'Score': 0.9999730595009302, 'Text': 'a customer'}, {'BeginOffset': 2697, 'EndOffset': 2707, 'Score': 0.9999624507401185, 'Text': 'your store'}, {'BeginOffset': 2727, 'EndOffset': 2737, 'Score': 0.9999479682286696, 'Text': 'the number'}, {'BeginOffset': 2741, 'EndOffset': 2750, 'Score': 0.9994831373662532, 'Text': 'transfers'}, {'BeginOffset': 2765, 'EndOffset': 2777, 'Score': 0.9998942141706304, 'Text': 'the customer'}, {'BeginOffset': 2786, 'EndOffset': 2825, 'Score': 0.9918136543186167, 'Text': 'the correct customer support department'}, {'BeginOffset': 2830, 'EndOffset': 2839, 'Score': 0.9995772365191326, 'Text': 'this case'}, {'BeginOffset': 2841, 'EndOffset': 2883, 'Score': 0.9764679733391671, 'Text': 'the different customer support departments'}, {'BeginOffset': 2894, 'EndOffset': 2905, 'Score': 0.9998709734691485, 'Text': 'the variety'}, {'BeginOffset': 2909, 'EndOffset': 2935, 'Score': 0.9994891464370124, 'Text': 'potential target variables'}, {'BeginOffset': 2951, 'EndOffset': 2977, 'Score': 0.994563292604083, 'Text': 'many different departments'}, {'BeginOffset': 2993, 'EndOffset': 3001, 'Score': 0.6399290646312936, 'Text': 'just two'}, {'BeginOffset': 3018, 'EndOffset': 3037, 'Score': 0.9971953650721751, 'Text': 'regression problems'}, {'BeginOffset': 3041, 'EndOffset': 3061, 'Score': 0.9999170417318082, 'Text': 'a regression problem'}, {'BeginOffset': 3088, 'EndOffset': 3096, 'Score': 0.9997508702786967, 'Text': 'an input'}, {'BeginOffset': 3100, 'EndOffset': 3116, 'Score': 0.9998969361434574, 'Text': 'a defined number'}, {'BeginOffset': 3120, 'EndOffset': 3130, 'Score': 0.9999315785515103, 'Text': 'categories'}, {'BeginOffset': 3155, 'EndOffset': 3163, 'Score': 0.9997207354324241, 'Text': 'an input'}, {'BeginOffset': 3167, 'EndOffset': 3185, 'Score': 0.9999460017482991, 'Text': 'a continuous value'}, {'BeginOffset': 3191, 'EndOffset': 3201, 'Score': 0.9999763972878256, 'Text': 'an integer'}, {'BeginOffset': 3203, 'EndOffset': 3214, 'Score': 0.9996504092135773, 'Text': 'one example'}, {'BeginOffset': 3218, 'EndOffset': 3242, 'Score': 0.9977877217770218, 'Text': 'an ml regression problem'}, {'BeginOffset': 3257, 'EndOffset': 3266, 'Score': 0.9999693643021434, 'Text': 'the price'}, {'BeginOffset': 3270, 'EndOffset': 3279, 'Score': 0.9999713908534654, 'Text': 'a company'}, {'BeginOffset': 3282, 'EndOffset': 3287, 'Score': 0.9999391474374054, 'Text': 'stock'}, {'BeginOffset': 3289, 'EndOffset': 3304, 'Score': 0.9992748064937836, 'Text': 'computer vision'}, {'BeginOffset': 3308, 'EndOffset': 3322, 'Score': 0.9999451272021559, 'Text': 'a good example'}, {'BeginOffset': 3326, 'EndOffset': 3345, 'Score': 0.9788476448942265, 'Text': 'supervised learning'}, {'BeginOffset': 3355, 'EndOffset': 3360, 'Score': 0.9929924934394466, 'Text': 'a cat'}, {'BeginOffset': 3364, 'EndOffset': 3369, 'Score': 0.9996348166356972, 'Text': 'a dog'}, {'BeginOffset': 3380, 'EndOffset': 3387, 'Score': 0.9949323798661655, 'Text': 'a tumor'}, {'BeginOffset': 3391, 'EndOffset': 3417, 'Score': 0.9988816104690696, 'Text': 'this x-ray computer vision'}, {'BeginOffset': 3438, 'EndOffset': 3458, 'Score': 0.971356283041699, 'Text': 'deep learning models'}, {'BeginOffset': 3473, 'EndOffset': 3530, 'Score': 0.9957142775771246, 'Text': 'the extraction analysis, classification and understanding'}, {'BeginOffset': 3534, 'EndOffset': 3552, 'Score': 0.9997238713740075, 'Text': 'useful information'}, {'BeginOffset': 3558, 'EndOffset': 3572, 'Score': 0.9999645166458594, 'Text': 'a single image'}, {'BeginOffset': 3576, 'EndOffset': 3586, 'Score': 0.9999402797846273, 'Text': 'a sequence'}, {'BeginOffset': 3590, 'EndOffset': 3596, 'Score': 0.9999717481958249, 'Text': 'images'}, {'BeginOffset': 3598, 'EndOffset': 3613, 'Score': 0.9998375517728273, 'Text': 'computer vision'}, {'BeginOffset': 3622, 'EndOffset': 3630, 'Score': 0.9998184772020393, 'Text': 'machines'}, {'BeginOffset': 3643, 'EndOffset': 3679, 'Score': 0.9820098263234851, 'Text': 'people, places and things and images'}, {'BeginOffset': 3685, 'EndOffset': 3693, 'Score': 0.9997803455340087, 'Text': 'accuracy'}, {'BeginOffset': 3706, 'EndOffset': 3718, 'Score': 0.9994812308016545, 'Text': 'human levels'}, {'BeginOffset': 3728, 'EndOffset': 3756, 'Score': 0.9945446395706983, 'Text': 'greater speed and efficiency'}, {'BeginOffset': 3758, 'EndOffset': 3772, 'Score': 0.99961068268507, 'Text': 'the image data'}, {'BeginOffset': 3782, 'EndOffset': 3792, 'Score': 0.9997928014935943, 'Text': 'many forms'}, {'BeginOffset': 3801, 'EndOffset': 3814, 'Score': 0.9995167316991588, 'Text': 'single images'}, {'BeginOffset': 3816, 'EndOffset': 3831, 'Score': 0.9997145177091662, 'Text': 'video sequences'}, {'BeginOffset': 3833, 'EndOffset': 3838, 'Score': 0.9653729200569273, 'Text': 'views'}, {'BeginOffset': 3844, 'EndOffset': 3860, 'Score': 0.9999676953755, 'Text': 'multiple cameras'}, {'BeginOffset': 3864, 'EndOffset': 3886, 'Score': 0.9998259456388723, 'Text': 'three dimensional data'}, {'BeginOffset': 3912, 'EndOffset': 3927, 'Score': 0.993454875125504, 'Text': 'computer vision'}, {'BeginOffset': 3938, 'EndOffset': 3949, 'Score': 0.9999626294700503, 'Text': 'this course'}, {'BeginOffset': 3969, 'EndOffset': 3998, 'Score': 0.7932621528416804, 'Text': 'unsupervised machine learning'}, {'BeginOffset': 4026, 'EndOffset': 4034, 'Score': 0.9998824180931911, 'Text': 'the data'}, {'BeginOffset': 4044, 'EndOffset': 4057, 'Score': 0.9984439514402218, 'Text': 'no supervisor'}, {'BeginOffset': 4061, 'EndOffset': 4069, 'Score': 0.9999361675128265, 'Text': 'the room'}, {'BeginOffset': 4073, 'EndOffset': 4101, 'Score': 0.8410306313036842, 'Text': 'unsupervised learning labels'}, {'BeginOffset': 4137, 'EndOffset': 4156, 'Score': 0.914326366173695, 'Text': 'supervised learning'}, {'BeginOffset': 4173, 'EndOffset': 4203, 'Score': 0.9851945333610143, 'Text': 'all the variables and patterns'}, {'BeginOffset': 4207, 'EndOffset': 4222, 'Score': 0.9999212698319815, 'Text': 'these instances'}, {'BeginOffset': 4224, 'EndOffset': 4235, 'Score': 0.9999628082318452, 'Text': 'the machine'}, {'BeginOffset': 4262, 'EndOffset': 4272, 'Score': 0.9993133489978068, 'Text': 'the labels'}, {'BeginOffset': 4281, 'EndOffset': 4293, 'Score': 0.9997836990466034, 'Text': 'these models'}, {'BeginOffset': 4298, 'EndOffset': 4306, 'Score': 0.9999406384529743, 'Text': 'the data'}, {'BeginOffset': 4340, 'EndOffset': 4359, 'Score': 0.9962491099931027, 'Text': 'emerging properties'}, {'BeginOffset': 4363, 'EndOffset': 4382, 'Score': 0.942007850057912, 'Text': 'the entire data set'}, {'BeginOffset': 4404, 'EndOffset': 4412, 'Score': 0.999757706237984, 'Text': 'patterns'}, {'BeginOffset': 4418, 'EndOffset': 4434, 'Score': 0.9997606356514069, 'Text': 'those properties'}, {'BeginOffset': 4436, 'EndOffset': 4446, 'Score': 0.9625664744804459, 'Text': 'clustering'}, {'BeginOffset': 4450, 'EndOffset': 4470, 'Score': 0.9999653511101213, 'Text': 'a common subcategory'}, {'BeginOffset': 4474, 'EndOffset': 4495, 'Score': 0.9536791222168228, 'Text': 'unsupervised learning'}, {'BeginOffset': 4497, 'EndOffset': 4506, 'Score': 0.9998850382819344, 'Text': 'this kind'}, {'BeginOffset': 4510, 'EndOffset': 4531, 'Score': 0.8928107658450388, 'Text': 'algorithm groups data'}, {'BeginOffset': 4537, 'EndOffset': 4555, 'Score': 0.9997782743423504, 'Text': 'different clusters'}, {'BeginOffset': 4565, 'EndOffset': 4581, 'Score': 0.9999576825143902, 'Text': 'similar features'}, {'BeginOffset': 4617, 'EndOffset': 4631, 'Score': 0.9998971362805013, 'Text': 'the attributes'}, {'BeginOffset': 4635, 'EndOffset': 4653, 'Score': 0.9999359108458893, 'Text': 'a specific cluster'}, {'BeginOffset': 4681, 'EndOffset': 4700, 'Score': 0.8533167529777693, 'Text': 'customer purchasing'}, {'BeginOffset': 4701, 'EndOffset': 4707, 'Score': 0.5292165646895304, 'Text': 'habits'}, {'BeginOffset': 4709, 'EndOffset': 4732, 'Score': 0.9990800986370661, 'Text': 'unsupervised algorithms'}, {'BeginOffset': 4746, 'EndOffset': 4752, 'Score': 0.9999634040871428, 'Text': 'groups'}, {'BeginOffset': 4756, 'EndOffset': 4765, 'Score': 0.9999855758836753, 'Text': 'customers'}, {'BeginOffset': 4791, 'EndOffset': 4804, 'Score': 0.9992697956686324, 'Text': 'the size tier'}, {'BeginOffset': 4808, 'EndOffset': 4817, 'Score': 0.9999875427991473, 'Text': 'a company'}, {'BeginOffset': 4819, 'EndOffset': 4832, 'Score': 0.999983489787026, 'Text': 'the advantage'}, {'BeginOffset': 4836, 'EndOffset': 4859, 'Score': 0.9997042175037948, 'Text': 'unsupervised algorithms'}, {'BeginOffset': 4891, 'EndOffset': 4899, 'Score': 0.9997504380345485, 'Text': 'patterns'}, {'BeginOffset': 4903, 'EndOffset': 4911, 'Score': 0.9999591133815197, 'Text': 'the data'}, {'BeginOffset': 4945, 'EndOffset': 4972, 'Score': 0.9982728035949393, 'Text': 'natural language processing'}, {'BeginOffset': 4990, 'EndOffset': 4994, 'Score': 0.8747893610987658, 'Text': 'n lp'}], 'location': [], 'organization': []}\n"
     ]
    }
   ],
   "source": [
    "transcription = mergedDf.iloc[3,2]\n",
    "keyphrases = mergedDf.iloc[3,4]\n",
    "location = mergedDf.iloc[3,6]\n",
    "organization = mergedDf.iloc[3,7]\n",
    "movie_name = mergedDf.iloc[3,1]\n",
    "\n",
    "document = {\"name\": movie_name, \"transcription\": transcription, \"keyphrases\": keyphrases, \"location\":location, \"organization\": organization}\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import helpers\n",
    "\n",
    "def gendata(start, stop):    \n",
    "    if stop>mergedDf.shape[0]:\n",
    "        stop = mergedDf.shape[0]\n",
    "    for i in range(start, stop):\n",
    "        yield {\n",
    "            \"_index\":'movies',\n",
    "            \"_type\": \"_doc\", \n",
    "            \"_id\":i, \n",
    "            \"_source\": {\"name\": mergedDf.iloc[i,1], \"transcription\": mergedDf.iloc[i,2], \"keyphrases\": mergedDf.iloc[i,4], \"location\":mergedDf.iloc[i,6], \"organization\": mergedDf.iloc[i,7]}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.1 ms, sys: 1.57 ms, total: 54.7 ms\n",
      "Wall time: 1.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(46, [])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, region, service, session_token=credentials.token)\n",
    "es = OpenSearch(\n",
    "    hosts = [{'host': es_endpoint, 'port': 443}],\n",
    "    http_auth = awsauth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")\n",
    "helpers.bulk(es, gendata(0,mergedDf.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Creating the Kibana dashboard#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://search-nlp-lab-2ji5uwg3obudwvrjwpvkxbmice.us-east-1.es.amazonaws.com/_plugin/kibana\n"
     ]
    }
   ],
   "source": [
    "print(f'https://{es_endpoint}/_plugin/kibana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### some cleanup #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = es_client.delete_elasticsearch_domain(\n",
    "    DomainName='nlp-lab'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You have completed this lab, and you can now end the lab by following the lab guide instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*©2023 Amazon Web Services, Inc. or its affiliates. All rights reserved. This work may not be reproduced or redistributed, in whole or in part, without prior written permission from Amazon Web Services, Inc. Commercial copying, lending, or selling is prohibited. All trademarks are the property of their owners.*\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b71a13339a0be9489ff337af97259fe0ed71e682663adc836bae31ac651d564e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
